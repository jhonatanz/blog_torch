<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Jhonatan Zambrano">

<title>torch_blog - Familiarizandose con tensores en torch</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la búsqueda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">torch_blog</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Familiarizandose con tensores en torch</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">torch</div>
                <div class="quarto-category">tensores</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Autor/a</div>
      <div class="quarto-title-meta-contents">
               <p>Jhonatan Zambrano </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Fecha de publicación</div>
      <div class="quarto-title-meta-contents">
        <p class="date">17 de enero de 2023</p>
      </div>
    </div>
    
      
    </div>
    
  <div>
    <div class="abstract">
      <div class="abstract-title">Resumen</div>
      Se presentan aquí las cosas principales que necesitas saber sobre los tensores de Torch. Como ejemplo ilustrativo se va a programar una red neuronal sencilla desde el principio.
    </div>
  </div>
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p><img src="tensor.png" class="img-fluid"></p>
<section id="introducción" class="level2">
<h2 class="anchored" data-anchor-id="introducción">Introducción</h2>
<p>Anteriormente se introdujo <strong>torch</strong>, un paquete de R que provee funcionalidad nativa similar a la que tienen los usuarios de Python por medio de PyTorch. Allí se asumió algún conocimiento de Keras y TensorFlow. Por lo anterior, se “retrató” torch de forma que pudiera ser de ayuda para alguien que haya “crecido” con la forma en que se entrena un modelo en Keras : enfocándose en las diferencias, sin perder de vista el proceso completo.</p>
<p>En esta publicación se cambia de perspectiva. Se programa una red neuronal sencilla “desde el principio” haciendo uso únicamente de uno de los bloques constructivos básicos de torch: <em>tensores</em>. Esta red sera tan de “bajo nivel” como puede es posible. (Para aquellos menos inclinados a las matemáticas, esto puede servir como un repaso sobre que es lo que ocurre realmente detrás de todas las herramientas que han sido convenientemente construidas para nosotros. Pero el propósito real es ilustrar todo lo que se puede hacer únicamente con tensores).</p>
<p>Posteriormente, se publicaran tres documentos que mostrarán progresivamente como se puede ir reduciendo el esfuerzo: notablemente desde el principio, enormemente una vez se hayan terminado. Al finalizar estas publicaciones habrás visto como la derivación automática funciona en torch, como usar módulos (capas, in el idioma de keras) y optimizadores. Para ese entonces, tendrás fuertes bases para ser usadas cuando se aplique torch al desarrollo de tareas del mundo real.</p>
<p>Esta publicación será la mas extensa, dado que hay mucho por aprender acerca de los tensores: como crearlos, como manipular sus contenidos o modificas sus formas, como convertirlos en arreglos de R, matrices o vectores, y por supuesto, dada la omnipresente necesidad de velocidad, como ejecutar todas estas operaciones en la GPU. Una vez cumplida la agenda, programaremos la mencionada red neuronal, observando todos estos aspectos en acción.</p>
</section>
<section id="tensores" class="level2">
<h2 class="anchored" data-anchor-id="tensores">Tensores</h2>
<section id="creación" class="level3">
<h3 class="anchored" data-anchor-id="creación">Creación</h3>
<p>Los tensores pueden ser creados especificando los valores individuales. aqui se crean dos tensores uni-dimensionales (vectores), de tipo “float” y “bool” respectivamente:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># un vector 1d de tamaño 2</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>t</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 1
 2
[ CPUFloatType{2} ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ahora un vector 1d, pero del tipo bool</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>t<span class="ot">&lt;-</span><span class="fu">torch_tensor</span>(<span class="fu">c</span>(<span class="cn">TRUE</span>, <span class="cn">FALSE</span>))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Y aquí se presentan dos modos de crear tensores bi-dimensionales (matrices). Note como en el segundo modo se necesita especificar <code>byrow = TRUE</code> en el llamado a <code>matrix()</code>para obtener los valores ordenados en orden fila-mayor.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># un tensor de 3x3 (matriz)</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(<span class="fu">rbind</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>), <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">0</span>, <span class="dv">0</span>), <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>)))</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>t</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 1  2  0
 3  0  0
 4  5  6
[ CPUFloatType{3,3} ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># otro tensor de 3x3</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(<span class="fu">matrix</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">9</span>, <span class="at">ncol =</span> <span class="dv">3</span>, <span class="at">byrow =</span> T))</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>t</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 1  2  3
 4  5  6
 7  8  9
[ CPULongType{3,3} ]</code></pre>
</div>
</div>
<p>Para dimensiones mas altas especialmente, puede se mas facil especificar el tipo de tensor de forma abstracta, como en: “dame un tensor de &lt;…&gt; de la forma n1 x n2” donde &lt;…&gt; puede ser “ceros”, “unos”, o por ejemplo, “valores muestreados de una distribución normal estándar”:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># un tensor de 3x3 de valores normalmente distribuidos</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">torch_randn</span>(<span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>t</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 1.6203 -0.7829 -0.7159
 1.3453 -1.6175 -0.3454
-1.6268 -0.2089 -0.2962
[ CPUFloatType{3,3} ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># un tensor de ceros de 4x2x2 (3d)</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">torch_zeros</span>(<span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>t</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
(1,.,.) = 
  0  0
  0  0

(2,.,.) = 
  0  0
  0  0

(3,.,.) = 
  0  0
  0  0

(4,.,.) = 
  0  0
  0  0
[ CPUFloatType{4,2,2} ]</code></pre>
</div>
</div>
<p>Existen muchas funciones similares, incluidas: <code>torch_arange()</code> para crear un tensor que mantiene una secuencia de valores igualmente espaciados, <code>torch_eye()</code> el cual retorna una matriz identidad y <code>torch_logspace()</code> que llena un rango especifico con una lista de valores espaciados logarítmicamente.</p>
<p>Si el argumento <code>dtype</code> no se especifica, <code>torch</code> inferirá el tipo de datos de los valores entregados. Por ejemplo:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(<span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">7</span>))</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>t<span class="sc">$</span>dtype</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_Float</code></pre>
</div>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(1L)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>t<span class="sc">$</span>dtype</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_Long</code></pre>
</div>
</div>
<p>Pero se puede definir explícitamente un <code>dtype</code> diferente si se desea:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(<span class="dv">1</span>, <span class="at">dtype =</span> <span class="fu">torch_double</span>())</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>t<span class="sc">$</span>dtype</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_Double</code></pre>
</div>
</div>
<p>Los tensores de <code>torch</code> residen en un <em>dispositivo</em>. Por defecto, será en la CPU:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>t<span class="sc">$</span>device</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_device(type='cpu')</code></pre>
</div>
</div>
<p>Aunque se puede definir un tensor que resida en la GPU:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(<span class="dv">2</span>, <span class="at">device =</span> <span class="st">"cuda"</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>t<span class="sc">$</span>device</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_device(type='cuda', index=0)</code></pre>
</div>
</div>
<p>Se hablará mas sobre los dispositivos mas adelante.</p>
<p>Hay otro parámetro importante en las funciones para creación de tensores: <code>requires_grad</code>. Sin embargo, aquí debemos apelar a la paciencia, este tema sera discutido de forma prominente en la siguiente publicación.</p>
</section>
<section id="conversión-a-tipos-de-datos-nativos-de-r" class="level3">
<h3 class="anchored" data-anchor-id="conversión-a-tipos-de-datos-nativos-de-r">Conversión a tipos de datos nativos de R</h3>
<p>Para convertir tensores <code>torch</code> a datos nativos de R se usa la función <code>as_array()</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(<span class="fu">matrix</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">9</span>, <span class="at">ncol =</span> <span class="dv">3</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>))</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="fu">as.array</span>(t)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2] [,3]
[1,]    1    2    3
[2,]    4    5    6
[3,]    7    8    9</code></pre>
</div>
</div>
<p>Dependiente de si el tensor es de una, dos o tres dimensiones, el objeto resultante nativo será un vector, una matriz o un arreglo:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>))</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="fu">as.array</span>(t) <span class="sc">%&gt;%</span> <span class="fu">class</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "numeric"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">torch_ones</span>(<span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="fu">as.array</span>(t) <span class="sc">%&gt;%</span> <span class="fu">class</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "matrix" "array" </code></pre>
</div>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">torch_ones</span>(<span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="fu">as.array</span>(t) <span class="sc">%&gt;%</span> <span class="fu">class</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "array"</code></pre>
</div>
</div>
<p>Para tensores de una o dos dimensiones, también es posible usar <code>as.integer()</code> o <code>as.matrix()</code>.</p>
<p>Si un tensor actualmente reside en la GPU, se requiere moverlo a la CPU primero:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(<span class="dv">2</span>, <span class="at">device =</span> <span class="st">"cuda"</span>)</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="fu">as.integer</span>(t<span class="sc">$</span><span class="fu">cpu</span>())</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2</code></pre>
</div>
</div>
</section>
<section id="indexado-y-seccionado-de-tensores" class="level3">
<h3 class="anchored" data-anchor-id="indexado-y-seccionado-de-tensores">Indexado y seccionado de tensores</h3>
<p>A menudo se desea obtener solo una parte de un tensor, incluso un único valor. En estos casos se habla de <em>seccionado</em> e <em>indexado</em> respectivamente.</p>
<p>En R, estas operaciones son <em>base-1</em> es decir, la primera posición de cualquier arreglo se identifica con el número 1 y no con el número 0. El mismo comportamiento fue implementado para <code>torch</code>. De este modo, muchas de la funcionalidad descrita en esta sección se podría sentir intuitiva.</p>
</section>
<section id="la-parte-similar-a-r" class="level3">
<h3 class="anchored" data-anchor-id="la-parte-similar-a-r">La parte similar a R</h3>
<p>Nada de lo siguiente debería parecer demasiado sorpresivo:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(<span class="fu">rbind</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>), <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>)))</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>t</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 1  2  3
 4  5  6
[ CPUFloatType{2,3} ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Un unico valor</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>t[<span class="dv">1</span>, <span class="dv">1</span>]</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
1
[ CPUFloatType{} ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># primera fila, todas las columnas</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>t[<span class="dv">1</span>, ]</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 1
 2
 3
[ CPUFloatType{3} ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># primera fila, un subconjunto de columnas</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>t[<span class="dv">1</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>]</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 1
 2
[ CPUFloatType{2} ]</code></pre>
</div>
</div>
<p>Nótese como, tal y como ocurre en R, las dimensiones son eliminadas</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(<span class="fu">rbind</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>), <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>)))</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 2x3</span></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>t<span class="sc">$</span><span class="fu">size</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2 3</code></pre>
</div>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Una sola fila: sera devuelto como un vector</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>t[<span class="dv">1</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>]<span class="sc">$</span><span class="fu">size</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2</code></pre>
</div>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Un solo elemento</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>t[<span class="dv">1</span>, <span class="dv">1</span>]<span class="sc">$</span><span class="fu">size</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>integer(0)</code></pre>
</div>
</div>
<p>Y al igual que en R, se pueden mantener las dimensiones originales si se especifica <code>drop = FALSE</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>t[<span class="dv">1</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>, drop <span class="ot">=</span> F]<span class="sc">$</span><span class="fu">size</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1 2</code></pre>
</div>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>t[<span class="dv">1</span>, <span class="dv">1</span>, drop <span class="ot">=</span> F]<span class="sc">$</span><span class="fu">size</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1 1</code></pre>
</div>
</div>
</section>
<section id="la-parte-distinta-a-r" class="level3">
<h3 class="anchored" data-anchor-id="la-parte-distinta-a-r">La parte distinta a R</h3>
<p>R usa números negativos para remover elementos en posiciones especificas, en <code>torch</code> los números negativos indican que se inicia contando desde el final de un tensor, siendo -1 el último elemento:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(<span class="fu">rbind</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>), <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>)))</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>t[<span class="dv">1</span>, <span class="sc">-</span><span class="dv">1</span>]</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
3
[ CPUFloatType{} ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>t[ , <span class="sc">-</span><span class="dv">2</span><span class="sc">:-</span><span class="dv">1</span>]</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 2  3
 5  6
[ CPUFloatType{2,2} ]</code></pre>
</div>
</div>
<p>Esta característica puede ser conocida de NumPy. Al igual que la siguiente:</p>
<p>Cuando la expresión de rebanado <code>m:n</code> se aumenta con un tercer numero <code>m:n:o</code> se tomará cada o-ésimo ítem del rango especificado por m y n:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>)</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>t[<span class="dv">2</span><span class="sc">:</span><span class="dv">10</span><span class="sc">:</span><span class="dv">2</span>]</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
  2
  4
  6
  8
 10
[ CPULongType{5} ]</code></pre>
</div>
</div>
<p>Algunas veces no se sabe cuantas dimensiones tiene un tensor, pero sí sabemos que hacer con la última dimensión, o la primera. Para obviar todas las otras podemos usar:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">torch_randint</span>(<span class="sc">-</span><span class="dv">7</span>, <span class="dv">7</span>, <span class="at">size =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>t</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
(1,.,.) = 
  5  5
  1 -1

(2,.,.) = 
 -1 -2
  4  5
[ CPUFloatType{2,2,2} ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>t[.., <span class="dv">1</span>]</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 5  1
-1  4
[ CPUFloatType{2,2} ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>t[<span class="dv">2</span>, ..]</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
-1 -2
 4  5
[ CPUFloatType{2,2} ]</code></pre>
</div>
</div>
<p>Pasamos ahora a un tema que, en la practica, es tan indispensable como el seccionamiento: cambios en la forma de los tensores.</p>
</section>
<section id="cambiando-la-forma-de-los-tensores" class="level3">
<h3 class="anchored" data-anchor-id="cambiando-la-forma-de-los-tensores">Cambiando la forma de los tensores</h3>
<p>Loa cambios en las formas de los tensores pueden ocurrir de dos formas fundamentalmente. Observando lo que el “reformado” es realmente: <em>mantener los valores pero modifica el arreglo</em>, podríamos ya sea, alterar como los valores están distribuidos físicamente, o mantener a estructura física como está y solo cambiar el “mapeo”, es decir, un cambio semántico.</p>
<p>En el primer caso, se debe apartar almacenamiento para dos tensores, la fuente y el destino, los elementos serán copiados del último al primero. En el segundo caso, físicamente solo habrá un tensor, referenciado por dos entidades lógicas con distintos metadatos.</p>
<p>No es de sorprenderse que por razones de rendimiento, sean preferidas las operaciones del segundo caso.</p>
<section id="reformado-copia-cero" class="level4">
<h4 class="anchored" data-anchor-id="reformado-copia-cero">Reformado copia cero</h4>
<p>Empezamos con métodos de copia cero, dado que serán usados siempre que podamos.</p>
<p>Un caso especial a menudo visto en la practica es adicionar o remover dimensiones con un solo elemento.</p>
<p><code>unsqueeze()</code> adiciona una dimensión de tamaño 1 a la posición especificada por <code>dim</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="ot">&lt;-</span> <span class="fu">torch_randint</span>(<span class="at">low =</span> <span class="dv">3</span>, <span class="at">high =</span> <span class="dv">7</span>, <span class="at">size =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">3</span>))</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>t1<span class="sc">$</span><span class="fu">size</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 3 3 3</code></pre>
</div>
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>t2 <span class="ot">&lt;-</span> t1<span class="sc">$</span><span class="fu">unsqueeze</span>(<span class="at">dim =</span> <span class="dv">1</span>)</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>t2<span class="sc">$</span><span class="fu">size</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1 3 3 3</code></pre>
</div>
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>t3 <span class="ot">&lt;-</span> t1<span class="sc">$</span><span class="fu">unsqueeze</span>(<span class="at">dim =</span> <span class="dv">2</span>)</span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>t3<span class="sc">$</span><span class="fu">size</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 3 1 3 3</code></pre>
</div>
</div>
<p>Por otro lado, <code>squeeze</code> remueve las dimensiones de tamaño 1:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>t4 <span class="ot">&lt;-</span> t3<span class="sc">$</span><span class="fu">squeeze</span>()</span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>t4<span class="sc">$</span><span class="fu">size</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 3 3 3</code></pre>
</div>
</div>
<p>Lo mismo puede conseguirse con <code>view()</code>, sin embargo, esta función es mucho mas general, aquí se permite reformar los datos a cualquier dimensionalidad válida (es decir que el número de elementos se mantiene igual).</p>
<p>A continuación tenemos un tensor 3x2 que se reforma a una de tamaño 2x3:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(<span class="fu">rbind</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">4</span>), <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">6</span>)))</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>t1</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 1  2
 3  4
 5  6
[ CPUFloatType{3,2} ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>t2 <span class="ot">&lt;-</span> t1<span class="sc">$</span><span class="fu">view</span>(<span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">3</span>))</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>t2</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 1  2  3
 4  5  6
[ CPUFloatType{2,3} ]</code></pre>
</div>
</div>
<p>Nótese que esto es diferente a transponer la matriz</p>
<p>En lugar de ir de 2 a 3 dimensiones, podemos “aplanar” una matriz a un vector.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>t4 <span class="ot">&lt;-</span> t1<span class="sc">$</span><span class="fu">view</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">6</span>))</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a>t4<span class="sc">$</span><span class="fu">size</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1 6</code></pre>
</div>
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>t4</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 1  2  3  4  5  6
[ CPUFloatType{1,6} ]</code></pre>
</div>
</div>
<p>En contraste con las operaciones de indexación, aqui no se pierde dimensiones.</p>
<p>Como se dijo anteriormente, las operaciones <code>squeeze()</code> o <code>view()</code> no crea copias. O dicho de otro modo: el tensor de salida comparte el almacenamineto con el tensor de entrada. Este hecho se puede verificar del siguiente modo:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a>t1<span class="sc">$</span><span class="fu">storage</span>()<span class="sc">$</span><span class="fu">data_ptr</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "0x556940983e40"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>t2<span class="sc">$</span><span class="fu">storage</span>()<span class="sc">$</span><span class="fu">data_ptr</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "0x556940983e40"</code></pre>
</div>
</div>
<p>Lo que difiere es los metadatos que <code>torch</code> mantiene acerca de los dos tensores. Aqui la información relevante es el <em>paso</em>:</p>
<p>El método <code>stride()</code> (<em>paso</em>) de un tensor revisa, para cada dimensión, cuantos elementos tienen que ser atravesados para llegar a su próximo elemento (fila o columna, en dos dimensiones). Para <code>t1</code>, de forma 3x2, tenemos que saltar sobre 2 elementos para llegar a la siguiente fila. Para llegar a la siguiente columna, solo tendríamos que saltar sobre un elemento:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a>t1<span class="sc">$</span><span class="fu">stride</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2 1</code></pre>
</div>
</div>
<p>Para <code>t2</code>, de la forma 3x2, la distancia entre los elementos columna es el mismo, pero la distancia entre filas es ahora 3:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a>t2<span class="sc">$</span><span class="fu">stride</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 3 1</code></pre>
</div>
</div>
<p>Mientras que las operaciones “cero-copia” son óptimas, hay casos donde no sirven.</p>
<p>Con <code>view()</code>, puede ocurrir cuando un tensor obtenido vía una operación (diferente a <code>view</code>) que previamente haya modificado el <em>stride o paso</em>. Un ejemplo puede ser <code>transpose()</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(<span class="fu">rbind</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">4</span>), <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">6</span>)))</span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>t1</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 1  2
 3  4
 5  6
[ CPUFloatType{3,2} ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>t1<span class="sc">$</span><span class="fu">stride</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2 1</code></pre>
</div>
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a>t2 <span class="ot">&lt;-</span> t1<span class="sc">$</span><span class="fu">t</span>()</span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>t2</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 1  3  5
 2  4  6
[ CPUFloatType{2,3} ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>t2<span class="sc">$</span><span class="fu">stride</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1 2</code></pre>
</div>
</div>
<p>En el lenguaje de <code>torch</code>, los tensores (como <code>t2</code>) que están reutilizando cosas almacenadas previamente (solo que leídas de forma distinta), se dice que no son contiguas. Un modo de reformarlos es usar la función <code>contiguous()</code> previamente. Esto lo veremos en la siguiente sección.</p>
</section>
<section id="reformado-con-copia" class="level4">
<h4 class="anchored" data-anchor-id="reformado-con-copia">Reformado con copia</h4>
<p>En el siguiente fragmento de codigo se falla al intentar reformar t2 usando <code>view()</code>, dado que el tensor ya contiene información que indica que los datos no deben ser leidos en su orden fisico.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(<span class="fu">rbind</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">4</span>), <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">6</span>)))</span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a>t2 <span class="ot">&lt;-</span> t1<span class="sc">$</span><span class="fu">t</span>()</span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-5"><a href="#cb94-5" aria-hidden="true" tabindex="-1"></a>t2<span class="sc">$</span><span class="fu">view</span>(<span class="dv">6</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>Error in (function (self, size) : view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
Exception raised from view_impl at ../aten/src/ATen/native/TensorShape.cpp:2674 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;) + 0x6b (0x7f384d8452eb in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0xd1 (0x7f384d840e41 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libc10.so)
frame #2: at::native::view(at::Tensor const&amp;, c10::ArrayRef&lt;long&gt;) + 0x325 (0x7f3820bad305 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)
frame #3: &lt;unknown function&gt; + 0x200b006 (0x7f382140b006 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)
frame #4: at::_ops::view::redispatch(c10::DispatchKeySet, at::Tensor const&amp;, c10::ArrayRef&lt;long&gt;) + 0x98 (0x7f3821275718 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)
frame #5: &lt;unknown function&gt; + 0x37902f5 (0x7f3822b902f5 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)
frame #6: &lt;unknown function&gt; + 0x3790699 (0x7f3822b90699 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)
frame #7: at::_ops::view::redispatch(c10::DispatchKeySet, at::Tensor const&amp;, c10::ArrayRef&lt;long&gt;) + 0x98 (0x7f3821275718 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)
frame #8: &lt;unknown function&gt; + 0x32b4588 (0x7f38226b4588 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)
frame #9: &lt;unknown function&gt; + 0x32b4a69 (0x7f38226b4a69 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)
frame #10: at::_ops::view::call(at::Tensor const&amp;, c10::ArrayRef&lt;long&gt;) + 0xe7 (0x7f38212a1327 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)
frame #11: at::Tensor::view(c10::ArrayRef&lt;long&gt;) const + 0x42 (0x7f384e6050ce in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/liblantern.so)
frame #12: _lantern_Tensor_view_tensor_intarrayref + 0x130 (0x7f384e3cf96d in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/liblantern.so)
frame #13: cpp_torch_method_view_self_Tensor_size_IntArrayRef(XPtrTorchTensor, XPtrTorchIntArrayRef) + 0x35 (0x7f3851c2ff65 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/libs/torchpkg.so)
frame #14: _torch_cpp_torch_method_view_self_Tensor_size_IntArrayRef + 0xa1 (0x7f3851996221 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/libs/torchpkg.so)
frame #15: &lt;unknown function&gt; + 0xf7b6c (0x7f385caf7b6c in /usr/lib/R/lib/libR.so)
frame #16: &lt;unknown function&gt; + 0xf80fd (0x7f385caf80fd in /usr/lib/R/lib/libR.so)
frame #17: &lt;unknown function&gt; + 0x1317b5 (0x7f385cb317b5 in /usr/lib/R/lib/libR.so)
frame #18: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)
frame #19: &lt;unknown function&gt; + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)
frame #20: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)
frame #21: Rf_eval + 0x2ac (0x7f385cb4ea1c in /usr/lib/R/lib/libR.so)
frame #22: &lt;unknown function&gt; + 0xc3227 (0x7f385cac3227 in /usr/lib/R/lib/libR.so)
frame #23: &lt;unknown function&gt; + 0x1317b5 (0x7f385cb317b5 in /usr/lib/R/lib/libR.so)
frame #24: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)
frame #25: &lt;unknown function&gt; + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)
frame #26: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)
frame #27: &lt;unknown function&gt; + 0x13ea30 (0x7f385cb3ea30 in /usr/lib/R/lib/libR.so)
frame #28: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)
frame #29: &lt;unknown function&gt; + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)
frame #30: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)
frame #31: &lt;unknown function&gt; + 0x13ea30 (0x7f385cb3ea30 in /usr/lib/R/lib/libR.so)
frame #32: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)
frame #33: &lt;unknown function&gt; + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)
frame #34: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)
frame #35: &lt;unknown function&gt; + 0x13ea30 (0x7f385cb3ea30 in /usr/lib/R/lib/libR.so)
frame #36: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)
frame #37: &lt;unknown function&gt; + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)
frame #38: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)
frame #39: &lt;unknown function&gt; + 0x13ea30 (0x7f385cb3ea30 in /usr/lib/R/lib/libR.so)
frame #40: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)
frame #41: &lt;unknown function&gt; + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)
frame #42: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)
frame #43: &lt;unknown function&gt; + 0x13ea30 (0x7f385cb3ea30 in /usr/lib/R/lib/libR.so)
frame #44: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)
frame #45: &lt;unknown function&gt; + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)
frame #46: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)
frame #47: &lt;unknown function&gt; + 0x13ea30 (0x7f385cb3ea30 in /usr/lib/R/lib/libR.so)
frame #48: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)
frame #49: &lt;unknown function&gt; + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)
frame #50: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)
frame #51: Rf_eval + 0x2ac (0x7f385cb4ea1c in /usr/lib/R/lib/libR.so)
frame #52: &lt;unknown function&gt; + 0x153fa7 (0x7f385cb53fa7 in /usr/lib/R/lib/libR.so)
frame #53: &lt;unknown function&gt; + 0x1317b5 (0x7f385cb317b5 in /usr/lib/R/lib/libR.so)
frame #54: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)
frame #55: &lt;unknown function&gt; + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)
frame #56: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)
frame #57: &lt;unknown function&gt; + 0x13ea30 (0x7f385cb3ea30 in /usr/lib/R/lib/libR.so)
frame #58: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)
frame #59: &lt;unknown function&gt; + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)
frame #60: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)
frame #61: &lt;unknown function&gt; + 0x13ea30 (0x7f385cb3ea30 in /usr/lib/R/lib/libR.so)
frame #62: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)
frame #63: &lt;unknown function&gt; + 0x14f294 (0x7f385cb4f294 in /usr/lib/R/lib/libR.so)</code></pre>
</div>
</div>
<p>Sin embargo, si primero llamamos <code>contiguous()</code>, un nuevo tensor es creado, el cual podra ser (virtualmente) reformado usando <code>view()</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>t3 <span class="ot">&lt;-</span> t2<span class="sc">$</span><span class="fu">contiguous</span>()</span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-3"><a href="#cb96-3" aria-hidden="true" tabindex="-1"></a>t3<span class="sc">$</span><span class="fu">view</span>(<span class="dv">6</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 1
 3
 5
 2
 4
 6
[ CPUFloatType{6} ]</code></pre>
</div>
</div>
<p>Alternativamente, podemos usar <code>reshape()</code>. Esta función se comportará similar a <code>view()</code> siempre que sea posible; de otro modo creará una copia física.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a>t2<span class="sc">$</span><span class="fu">storage</span>()<span class="sc">$</span><span class="fu">data_ptr</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "0x556945ddf9c0"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a>t4 <span class="ot">&lt;-</span> t2<span class="sc">$</span><span class="fu">reshape</span>(<span class="dv">6</span>)</span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a>t2<span class="sc">$</span><span class="fu">storage</span>()<span class="sc">$</span><span class="fu">data_ptr</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "0x556945ddf9c0"</code></pre>
</div>
</div>
</section>
</section>
<section id="operaciones-con-tensores" class="level3">
<h3 class="anchored" data-anchor-id="operaciones-con-tensores">Operaciones con tensores</h3>
<p>No es para sorprenderse que <code>torch</code> provea una cantidad de operaciones con tensores; veremos algunos de ellos en el código de la red que se desarrollará luego y se encontrarán muchos mas con el uso de <code>torch</code>. Aquí echaremos un vistazo general a la semántica de los métodos de los tensores.</p>
<p>Los métodos de los tensores normalmente retornan referencias a nuevos objetos. A continuación se suma a <code>t1</code> un clon de si mismo:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(<span class="fu">rbind</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">4</span>), <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">6</span>)))</span>
<span id="cb102-2"><a href="#cb102-2" aria-hidden="true" tabindex="-1"></a>t2 <span class="ot">&lt;-</span> t1<span class="sc">$</span><span class="fu">clone</span>()</span>
<span id="cb102-3"><a href="#cb102-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb102-4"><a href="#cb102-4" aria-hidden="true" tabindex="-1"></a>t1<span class="sc">$</span><span class="fu">add</span>(t2)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
  2   4
  6   8
 10  12
[ CPUFloatType{3,2} ]</code></pre>
</div>
</div>
<p>En este proceso, <code>t1</code> no ha sido modificado:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a>t1</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 1  2
 3  4
 5  6
[ CPUFloatType{3,2} ]</code></pre>
</div>
</div>
<p>Muchos métodos tienen variantes para operaciones de “mutación”. Todas estas incluyen un guion bajo:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a>t1<span class="sc">$</span><span class="fu">add_</span>(t1)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
  2   4
  6   8
 10  12
[ CPUFloatType{3,2} ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Esta vez t1 es modificado</span></span>
<span id="cb108-2"><a href="#cb108-2" aria-hidden="true" tabindex="-1"></a>t1</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
  2   4
  6   8
 10  12
[ CPUFloatType{3,2} ]</code></pre>
</div>
</div>
<p>Alternativamente, se puede asignar el nuevo objeto a una nueva referencia de variable:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb110"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a>t3 <span class="ot">&lt;-</span> t1<span class="sc">$</span><span class="fu">add</span>(t1)</span>
<span id="cb110-2"><a href="#cb110-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb110-3"><a href="#cb110-3" aria-hidden="true" tabindex="-1"></a>t3</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
  4   8
 12  16
 20  24
[ CPUFloatType{3,2} ]</code></pre>
</div>
</div>
<p>Tenemos ahora una cosa que discutir antes de cerrar esta introducción a los tensores: ¿Como podemos ejecutar todas estas operaciones en la GPU?</p>
</section>
<section id="ejecutando-en-la-gpu" class="level3">
<h3 class="anchored" data-anchor-id="ejecutando-en-la-gpu">Ejecutando en la GPU</h3>
<p>Para verificar si hay una GPU visible para <code>torch</code>, ejecutar:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb112"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cuda_is_available</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] TRUE</code></pre>
</div>
<div class="sourceCode cell-code" id="cb114"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cuda_device_count</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1</code></pre>
</div>
</div>
<p>Los tensores pueden ser almacenado en la GPU directamente desde su creación</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb116"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a>device <span class="ot">&lt;-</span> <span class="fu">torch_device</span>(<span class="st">"cuda"</span>)</span>
<span id="cb116-2"><a href="#cb116-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb116-3"><a href="#cb116-3" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">torch_ones</span>(<span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>), <span class="at">device =</span> device)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>También pueden ser movidos entre dispositivos en cualquier momento:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb117"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a>t2 <span class="ot">&lt;-</span> t<span class="sc">$</span><span class="fu">cuda</span>()</span>
<span id="cb117-2"><a href="#cb117-2" aria-hidden="true" tabindex="-1"></a>t2<span class="sc">$</span>device</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_device(type='cuda', index=0)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb119"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a>t3 <span class="ot">&lt;-</span> t2<span class="sc">$</span><span class="fu">cpu</span>()</span>
<span id="cb119-2"><a href="#cb119-2" aria-hidden="true" tabindex="-1"></a>t3<span class="sc">$</span>device</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_device(type='cpu')</code></pre>
</div>
</div>
<p>Estamos por concluir la discusión sobre tensores. Hay una característica mas de <code>torch</code> que, a pesar de estar relacionada con operaciones con tensores, merece una mención especial. Es conocida como broadcasting (difusión).</p>
</section>
<section id="broadcasting" class="level3">
<h3 class="anchored" data-anchor-id="broadcasting">Broadcasting</h3>
<p>A menudo ejecutamos operaciones en tensores cuyas formas no concuerdan con exactitud.</p>
<p>Por ejemplo, podemos sumar un escalar con un tensor:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb121"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="ot">&lt;-</span> <span class="fu">torch_randn</span>(<span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">5</span>))</span>
<span id="cb121-2"><a href="#cb121-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb121-3"><a href="#cb121-3" aria-hidden="true" tabindex="-1"></a>t1<span class="sc">+</span><span class="dv">22</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 23.3398  22.0977  21.5262  22.2440  20.0809
 22.2100  21.8822  23.0445  21.1448  22.8481
 22.9730  20.9074  22.9415  21.9149  21.4249
[ CPUFloatType{3,5} ]</code></pre>
</div>
</div>
<p>También funciona si sumamos un tensor de tamaño 1</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb123"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb123-1"><a href="#cb123-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="sc">+</span> <span class="fu">torch_tensor</span>(<span class="fu">c</span>(<span class="dv">22</span>))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 23.3398  22.0977  21.5262  22.2440  20.0809
 22.2100  21.8822  23.0445  21.1448  22.8481
 22.9730  20.9074  22.9415  21.9149  21.4249
[ CPUFloatType{3,5} ]</code></pre>
</div>
</div>
<p>la suma de tensores de diferentes tamaños normalmente no funcionan:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="ot">&lt;-</span> <span class="fu">torch_randn</span>(<span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">5</span>))</span>
<span id="cb125-2"><a href="#cb125-2" aria-hidden="true" tabindex="-1"></a>t2 <span class="ot">&lt;-</span> <span class="fu">torch_randn</span>(<span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">5</span>))</span>
<span id="cb125-3"><a href="#cb125-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb125-4"><a href="#cb125-4" aria-hidden="true" tabindex="-1"></a>t1<span class="sc">$</span><span class="fu">add</span>(t2)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>Error in (function (self, other, alpha) : The size of tensor a (3) must match the size of tensor b (5) at non-singleton dimension 0
Exception raised from infer_size_impl at ../aten/src/ATen/ExpandUtils.cpp:35 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;) + 0x6b (0x7f384d8452eb in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;) + 0xce (0x7f384d840cbe in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libc10.so)
frame #2: at::infer_size_dimvector(c10::ArrayRef&lt;long&gt;, c10::ArrayRef&lt;long&gt;) + 0x48b (0x7f382061e32b in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)
frame #3: at::TensorIteratorBase::compute_shape(at::TensorIteratorConfig const&amp;) + 0x10d (0x7f38206713cd in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)
frame #4: at::TensorIteratorBase::build(at::TensorIteratorConfig&amp;) + 0x69 (0x7f3820672609 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)
frame #5: at::TensorIteratorBase::build_borrowing_binary_op(at::TensorBase const&amp;, at::TensorBase const&amp;, at::TensorBase const&amp;) + 0xf7 (0x7f3820673de7 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)
frame #6: at::meta::structured_add_Tensor::meta(at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;) + 0x2f (0x7f382084183f in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)
frame #7: &lt;unknown function&gt; + 0x20415e6 (0x7f38214415e6 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)
frame #8: &lt;unknown function&gt; + 0x20416e6 (0x7f38214416e6 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)
frame #9: at::_ops::add_Tensor::redispatch(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;) + 0x98 (0x7f3821148cf8 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)
frame #10: &lt;unknown function&gt; + 0x319a8ca (0x7f382259a8ca in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)
frame #11: &lt;unknown function&gt; + 0x319b049 (0x7f382259b049 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)
frame #12: at::_ops::add_Tensor::call(at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;) + 0x173 (0x7f3821177cc3 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)
frame #13: at::Tensor::add(at::Tensor const&amp;, c10::Scalar const&amp;) const + 0x3f (0x7f384e5fc0ef in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/liblantern.so)
frame #14: _lantern_Tensor_add_tensor_tensor_scalar + 0x13f (0x7f384e173b3b in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/liblantern.so)
frame #15: cpp_torch_method_add_self_Tensor_other_Tensor(XPtrTorchTensor, XPtrTorchTensor, XPtrTorchScalar) + 0x3b (0x7f3851c4fedb in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/libs/torchpkg.so)
frame #16: _torch_cpp_torch_method_add_self_Tensor_other_Tensor + 0xb9 (0x7f3851945d99 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/libs/torchpkg.so)
frame #17: &lt;unknown function&gt; + 0xf7b50 (0x7f385caf7b50 in /usr/lib/R/lib/libR.so)
frame #18: &lt;unknown function&gt; + 0xf80fd (0x7f385caf80fd in /usr/lib/R/lib/libR.so)
frame #19: &lt;unknown function&gt; + 0x1317b5 (0x7f385cb317b5 in /usr/lib/R/lib/libR.so)
frame #20: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)
frame #21: &lt;unknown function&gt; + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)
frame #22: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)
frame #23: Rf_eval + 0x2ac (0x7f385cb4ea1c in /usr/lib/R/lib/libR.so)
frame #24: &lt;unknown function&gt; + 0xc3227 (0x7f385cac3227 in /usr/lib/R/lib/libR.so)
frame #25: &lt;unknown function&gt; + 0x1317b5 (0x7f385cb317b5 in /usr/lib/R/lib/libR.so)
frame #26: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)
frame #27: &lt;unknown function&gt; + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)
frame #28: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)
frame #29: &lt;unknown function&gt; + 0x13ea30 (0x7f385cb3ea30 in /usr/lib/R/lib/libR.so)
frame #30: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)
frame #31: &lt;unknown function&gt; + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)
frame #32: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)
frame #33: &lt;unknown function&gt; + 0x13ea30 (0x7f385cb3ea30 in /usr/lib/R/lib/libR.so)
frame #34: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)
frame #35: &lt;unknown function&gt; + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)
frame #36: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)
frame #37: &lt;unknown function&gt; + 0x13ea30 (0x7f385cb3ea30 in /usr/lib/R/lib/libR.so)
frame #38: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)
frame #39: &lt;unknown function&gt; + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)
frame #40: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)
frame #41: &lt;unknown function&gt; + 0x13ea30 (0x7f385cb3ea30 in /usr/lib/R/lib/libR.so)
frame #42: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)
frame #43: &lt;unknown function&gt; + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)
frame #44: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)
frame #45: Rf_eval + 0x2ac (0x7f385cb4ea1c in /usr/lib/R/lib/libR.so)
frame #46: &lt;unknown function&gt; + 0x153fa7 (0x7f385cb53fa7 in /usr/lib/R/lib/libR.so)
frame #47: &lt;unknown function&gt; + 0x1317b5 (0x7f385cb317b5 in /usr/lib/R/lib/libR.so)
frame #48: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)
frame #49: &lt;unknown function&gt; + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)
frame #50: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)
frame #51: &lt;unknown function&gt; + 0x13ea30 (0x7f385cb3ea30 in /usr/lib/R/lib/libR.so)
frame #52: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)
frame #53: &lt;unknown function&gt; + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)
frame #54: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)
frame #55: &lt;unknown function&gt; + 0x13ea30 (0x7f385cb3ea30 in /usr/lib/R/lib/libR.so)
frame #56: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)
frame #57: &lt;unknown function&gt; + 0x14f294 (0x7f385cb4f294 in /usr/lib/R/lib/libR.so)
frame #58: Rf_eval + 0x39e (0x7f385cb4eb0e in /usr/lib/R/lib/libR.so)
frame #59: &lt;unknown function&gt; + 0x1547c0 (0x7f385cb547c0 in /usr/lib/R/lib/libR.so)
frame #60: &lt;unknown function&gt; + 0x192f17 (0x7f385cb92f17 in /usr/lib/R/lib/libR.so)
frame #61: &lt;unknown function&gt; + 0x130cc8 (0x7f385cb30cc8 in /usr/lib/R/lib/libR.so)
frame #62: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)
frame #63: &lt;unknown function&gt; + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)</code></pre>
</div>
</div>
<p>Sin embargo, bajo ciertas condiciones, uno o los dos tensores pueden ser expandidos virtualmente de forma que se alinean. Este comportamiento es lo que se denomina <em>broadcasting</em>. La forma en que esto funciona en <code>torch</code> no solo se inspira en NumPy, es idéntica.</p>
<p>Las reglas son las siguientes:</p>
<ol type="1">
<li>Se alinean las formas de los arreglos empezando desde la derecha: Digamos que se tienen dos tensores, uno de la forma 8x1x6x1 y otro de 7x1x5:</li>
</ol>
<p>forma t1: 8 1 6 1 forma t2: 7 1 5</p>
<ol start="2" type="1">
<li>Mirando desde la derecha, los tamaños a lo largo de los ejes alineados: o son iguales o uno de ellos es igual a 1, en cuyo caso el ultimo es ampliado al tamaño del mayor. En nuestro ejemplo tendríamos:</li>
</ol>
<p>forma t1: 8 1 6 1 forma t2: 7 6 5</p>
<p>Con el broadcasting ocurriendo en t2.</p>
<ol start="3" type="1">
<li>Si en el lado izquierdo, uno de los arreglos tiene un eje adicional (o mas de uno) el otro arreglo es virtualmente expandido para tener un tamaño de 1 es ese eje.</li>
</ol>
<p>forma t1: 8 1 6 1 forma t2: 1 7 1 5</p>
<p>y luego ocurre el broadcast:</p>
<p>forma t1: 8 1 6 1 forma t2: 8 7 1 5</p>
<p>De acuerdo con las anteriores reglas el ejemplo de sumar dos tensores de formas: 3x5 y 5x5 se podría modificar para permitir la suma de dos tensores.</p>
<p>Por ejemplo, si t2 fuera 1x5, solo se requeriría ampliar a una forma de 3x5 antes de la operación suma:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb127"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="ot">&lt;-</span> <span class="fu">torch_randn</span>(<span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">5</span>))</span>
<span id="cb127-2"><a href="#cb127-2" aria-hidden="true" tabindex="-1"></a>t2 <span class="ot">&lt;-</span> <span class="fu">torch_randn</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">5</span>))</span>
<span id="cb127-3"><a href="#cb127-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb127-4"><a href="#cb127-4" aria-hidden="true" tabindex="-1"></a>t1<span class="sc">$</span><span class="fu">add</span>(t2)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 1.2613 -1.5797 -0.1304  0.8364  1.4811
 2.0772 -0.5352 -0.1203 -0.3383  2.0498
 3.3027 -1.4875 -0.3475 -0.1763  1.0905
[ CPUFloatType{3,5} ]</code></pre>
</div>
</div>
<p>Si fuera de tamaño 5, una dimensión antecesora virtual podría ser añadida y entonces, el mismo broadcasting podría tomar lugar como en el caso anterior.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb129"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="ot">&lt;-</span> <span class="fu">torch_randn</span>(<span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">5</span>))</span>
<span id="cb129-2"><a href="#cb129-2" aria-hidden="true" tabindex="-1"></a>t2 <span class="ot">&lt;-</span> <span class="fu">torch_randn</span>(<span class="fu">c</span>(<span class="dv">5</span>))</span>
<span id="cb129-3"><a href="#cb129-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-4"><a href="#cb129-4" aria-hidden="true" tabindex="-1"></a>t1<span class="sc">$</span><span class="fu">add</span>(t2)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 0.6716  0.7809 -0.6019 -0.6897 -0.2175
-2.2945  2.2061 -2.8415  3.0838 -1.1119
 0.0464 -0.0846  0.1769  0.8541 -0.1863
[ CPUFloatType{3,5} ]</code></pre>
</div>
</div>
<p>A continuación un ejemplo mas complejo. Como ocurre un broadcasting en t1 y t2:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb131"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="ot">&lt;-</span> <span class="fu">torch_randn</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">5</span>))</span>
<span id="cb131-2"><a href="#cb131-2" aria-hidden="true" tabindex="-1"></a>t2 <span class="ot">&lt;-</span> <span class="fu">torch_randn</span>(<span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">1</span>))</span>
<span id="cb131-3"><a href="#cb131-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-4"><a href="#cb131-4" aria-hidden="true" tabindex="-1"></a>t1<span class="sc">$</span><span class="fu">add</span>(t2)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 0.3926 -0.4045 -0.5845 -1.5759  0.9646
 0.0973 -0.6997 -0.8798 -1.8711  0.6694
 1.8763  1.0792  0.8991 -0.0922  2.4483
[ CPUFloatType{3,5} ]</code></pre>
</div>
</div>
<p>Como ejemplo conclusivo, un producto exterior se puede computar a traves de broadcasting como sigue:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb133"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">30</span>))</span>
<span id="cb133-2"><a href="#cb133-2" aria-hidden="true" tabindex="-1"></a>t2 <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>))</span>
<span id="cb133-3"><a href="#cb133-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-4"><a href="#cb133-4" aria-hidden="true" tabindex="-1"></a>t1<span class="sc">$</span><span class="fu">view</span>(<span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">1</span>)) <span class="sc">*</span> t2</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
  0   0   0
 10  20  30
 20  40  60
 30  60  90
[ CPUFloatType{4,3} ]</code></pre>
</div>
</div>
<p>Ahora si, estamos listos para implementar una red neuronal!</p>
</section>
</section>
<section id="red-neuronal-simple-usando-tensores" class="level2">
<h2 class="anchored" data-anchor-id="red-neuronal-simple-usando-tensores">Red Neuronal Simple Usando Tensores</h2>
<p>Nuestra tarea, para la cual sera usado una aproximación de bajo nivel y que será simplificada considerablemente en próximos desarrollos, consiste en hacer la regresión de una variable de salida basados en tres variables de entrada.</p>
<p>Se usa <em>torch</em> directamente para simular algunos datos.</p>
<section id="datos" class="level3">
<h3 class="anchored" data-anchor-id="datos">Datos</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb135"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a><span class="co"># dimensión de la entrada</span></span>
<span id="cb135-2"><a href="#cb135-2" aria-hidden="true" tabindex="-1"></a>d_in <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb135-3"><a href="#cb135-3" aria-hidden="true" tabindex="-1"></a><span class="co"># dimensión de la salida</span></span>
<span id="cb135-4"><a href="#cb135-4" aria-hidden="true" tabindex="-1"></a>d_out <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb135-5"><a href="#cb135-5" aria-hidden="true" tabindex="-1"></a><span class="co"># cantidad de observaciones en el conjunto de entrenamiento</span></span>
<span id="cb135-6"><a href="#cb135-6" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb135-7"><a href="#cb135-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-8"><a href="#cb135-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Creación de datos aleatorios</span></span>
<span id="cb135-9"><a href="#cb135-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Entrada</span></span>
<span id="cb135-10"><a href="#cb135-10" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">torch_randn</span>(n, d_in)</span>
<span id="cb135-11"><a href="#cb135-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Salida</span></span>
<span id="cb135-12"><a href="#cb135-12" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> x[, <span class="dv">1</span>, drop <span class="ot">=</span> F] <span class="sc">*</span> <span class="fl">0.2</span> <span class="sc">-</span></span>
<span id="cb135-13"><a href="#cb135-13" aria-hidden="true" tabindex="-1"></a>  x[, <span class="dv">2</span>, drop <span class="ot">=</span> F] <span class="sc">*</span> <span class="fl">1.3</span> <span class="sc">-</span></span>
<span id="cb135-14"><a href="#cb135-14" aria-hidden="true" tabindex="-1"></a>  x[, <span class="dv">3</span>, drop <span class="ot">=</span> F] <span class="sc">*</span> <span class="fl">0.5</span> <span class="sc">+</span></span>
<span id="cb135-15"><a href="#cb135-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">torch_randn</span>(n, <span class="dv">1</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Ahora, se requiere inicializar los pesos de la red. Tendremos una capa oculta con 32 unidades. El tamaño de la capa de salida, determinada por la tarea, es igual a 1.</p>
</section>
<section id="inicializar-pesos" class="level3">
<h3 class="anchored" data-anchor-id="inicializar-pesos">Inicializar Pesos</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb136"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb136-1"><a href="#cb136-1" aria-hidden="true" tabindex="-1"></a><span class="co"># dimensiones del la capa oculta</span></span>
<span id="cb136-2"><a href="#cb136-2" aria-hidden="true" tabindex="-1"></a>d_hidden <span class="ot">&lt;-</span> <span class="dv">32</span></span>
<span id="cb136-3"><a href="#cb136-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb136-4"><a href="#cb136-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Pesos que conectan la entrada con la capa oculta</span></span>
<span id="cb136-5"><a href="#cb136-5" aria-hidden="true" tabindex="-1"></a>w1 <span class="ot">&lt;-</span> <span class="fu">torch_randn</span>(d_in, d_hidden)</span>
<span id="cb136-6"><a href="#cb136-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Pesos que conectan la capa oculta con la salida</span></span>
<span id="cb136-7"><a href="#cb136-7" aria-hidden="true" tabindex="-1"></a>w2 <span class="ot">&lt;-</span> <span class="fu">torch_randn</span>(d_hidden, d_out)</span>
<span id="cb136-8"><a href="#cb136-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb136-9"><a href="#cb136-9" aria-hidden="true" tabindex="-1"></a><span class="co"># sesgos de la capa oculta</span></span>
<span id="cb136-10"><a href="#cb136-10" aria-hidden="true" tabindex="-1"></a>b1 <span class="ot">&lt;-</span> <span class="fu">torch_zeros</span>(<span class="dv">1</span>, d_hidden)</span>
<span id="cb136-11"><a href="#cb136-11" aria-hidden="true" tabindex="-1"></a><span class="co"># sesgos de la salida</span></span>
<span id="cb136-12"><a href="#cb136-12" aria-hidden="true" tabindex="-1"></a>b2 <span class="ot">&lt;-</span> <span class="fu">torch_zeros</span>(<span class="dv">1</span>, d_out)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Ahora vamos a hacer el ciclo de entrenamiento propiamente. El ciclo de entrenamiento es, en realidad, la red neuronal.</p>
</section>
<section id="ciclo-de-entrenamiento" class="level3">
<h3 class="anchored" data-anchor-id="ciclo-de-entrenamiento">Ciclo de entrenamiento</h3>
<p>En cada iteración (época), el ciclo de entrenamiento hace cuatro cosas:</p>
<ul>
<li>Se hace la propagación hacia adelante, se computa las predicciones</li>
<li>Se comparan las predicciones con las salidas reales y se cuantifica la perdida</li>
<li>se hace la propagación hacia atrás en la red, se calculan los gradientes que indican como deben cambiarse los pesos</li>
<li>Se actualizan los pesos, haciendo uso de la tasa de aprendizaje.</li>
</ul>
<p>El formato seria como se muestra a continuación:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb137"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb137-1"><a href="#cb137-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">200</span>) {</span>
<span id="cb137-2"><a href="#cb137-2" aria-hidden="true" tabindex="-1"></a>  <span class="do">### -------------- Propagación hacia adelante ---------------</span></span>
<span id="cb137-3"><a href="#cb137-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Aquí vamos a calcular la predicción</span></span>
<span id="cb137-4"><a href="#cb137-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb137-5"><a href="#cb137-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb137-6"><a href="#cb137-6" aria-hidden="true" tabindex="-1"></a>  <span class="do">### -------------- Calculo de la perdida --------------------</span></span>
<span id="cb137-7"><a href="#cb137-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Aquí vamos a calcular la suma de los errores al cuadrado</span></span>
<span id="cb137-8"><a href="#cb137-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb137-9"><a href="#cb137-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb137-10"><a href="#cb137-10" aria-hidden="true" tabindex="-1"></a>  <span class="do">### -------------- Propagación hacia atrás ------------------</span></span>
<span id="cb137-11"><a href="#cb137-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Aquí vamos a propagar hacia atrás para calcular los gradientes</span></span>
<span id="cb137-12"><a href="#cb137-12" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb137-13"><a href="#cb137-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb137-14"><a href="#cb137-14" aria-hidden="true" tabindex="-1"></a>  <span class="do">### -------------- Actualización de los pesos ---------------</span></span>
<span id="cb137-15"><a href="#cb137-15" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Aquí vamos a actualizar los pesos, substrayendo una porción de los gradientes</span></span>
<span id="cb137-16"><a href="#cb137-16" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb137-17"><a href="#cb137-17" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb137-18"><a href="#cb137-18" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>La propagación hacia adelante efectúa dos transformaciones afines, una para la capa oculta y otra para la capa de salida. En el intermedio se aplica una activación ReLU:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb138"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb138-1"><a href="#cb138-1" aria-hidden="true" tabindex="-1"></a><span class="co"># calculo de las pre-activaciones de las capas ocultas (dim: 100 x 32)</span></span>
<span id="cb138-2"><a href="#cb138-2" aria-hidden="true" tabindex="-1"></a><span class="co"># torch_mm hace multiplicación de matrices</span></span>
<span id="cb138-3"><a href="#cb138-3" aria-hidden="true" tabindex="-1"></a>h <span class="ot">&lt;-</span> x<span class="sc">$</span><span class="fu">mm</span>(w1) <span class="sc">+</span> b1</span>
<span id="cb138-4"><a href="#cb138-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb138-5"><a href="#cb138-5" aria-hidden="true" tabindex="-1"></a><span class="co"># se aplica la función de activación (dim: 100 x 32)</span></span>
<span id="cb138-6"><a href="#cb138-6" aria-hidden="true" tabindex="-1"></a><span class="co"># torch_clamp corta los valores arriba/abajo de limites dados</span></span>
<span id="cb138-7"><a href="#cb138-7" aria-hidden="true" tabindex="-1"></a>h_relu <span class="ot">&lt;-</span> h<span class="sc">$</span><span class="fu">clamp</span>(<span class="at">min =</span> <span class="dv">0</span>)</span>
<span id="cb138-8"><a href="#cb138-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb138-9"><a href="#cb138-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculo de la salida (dim: 100 x 1)</span></span>
<span id="cb138-10"><a href="#cb138-10" aria-hidden="true" tabindex="-1"></a>y_pred <span class="ot">&lt;-</span> h_relu<span class="sc">$</span><span class="fu">mm</span>(w2) <span class="sc">+</span> b2</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Nuestra función de perdidas es el error cuadrático medio</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb139"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb139-1"><a href="#cb139-1" aria-hidden="true" tabindex="-1"></a>loss <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>((y_pred <span class="sc">-</span> y)<span class="sc">$</span><span class="fu">pow</span>(<span class="dv">2</span>)<span class="sc">$</span><span class="fu">sum</span>())</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>El calculo manual de los gradientes es un poco tedioso, pero puede ser realizado:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb140"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb140-1"><a href="#cb140-1" aria-hidden="true" tabindex="-1"></a><span class="co"># gradiente de perdidas w.r.t predicción (dim: 100 x 1)</span></span>
<span id="cb140-2"><a href="#cb140-2" aria-hidden="true" tabindex="-1"></a>grad_y_pred <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> (y_pred <span class="sc">-</span> y)</span>
<span id="cb140-3"><a href="#cb140-3" aria-hidden="true" tabindex="-1"></a><span class="co"># gradiente de perdidas w.r.t w2 (dim: 32 x 1)</span></span>
<span id="cb140-4"><a href="#cb140-4" aria-hidden="true" tabindex="-1"></a>grad_w2 <span class="ot">&lt;-</span> h_relu<span class="sc">$</span><span class="fu">t</span>()<span class="sc">$</span><span class="fu">mm</span>(grad_y_pred)</span>
<span id="cb140-5"><a href="#cb140-5" aria-hidden="true" tabindex="-1"></a><span class="co"># gradiente de perdidas w.r.t activación capa oculta (dim: 100 x 32)</span></span>
<span id="cb140-6"><a href="#cb140-6" aria-hidden="true" tabindex="-1"></a>grad_h_relu <span class="ot">&lt;-</span> grad_y_pre<span class="sc">$</span><span class="fu">mm</span>(w2<span class="sc">$</span><span class="fu">t</span>())</span>
<span id="cb140-7"><a href="#cb140-7" aria-hidden="true" tabindex="-1"></a><span class="co"># gradiente de perdidas w.r.t pre-activación capa oculta (dim: 100 x 32)</span></span>
<span id="cb140-8"><a href="#cb140-8" aria-hidden="true" tabindex="-1"></a>grad_h <span class="ot">&lt;-</span> grad_h_relu<span class="sc">$</span><span class="fu">clone</span>()</span>
<span id="cb140-9"><a href="#cb140-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb140-10"><a href="#cb140-10" aria-hidden="true" tabindex="-1"></a>grad_h[h <span class="sc">&lt;</span> <span class="dv">0</span>] <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb140-11"><a href="#cb140-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb140-12"><a href="#cb140-12" aria-hidden="true" tabindex="-1"></a><span class="co"># gradiente de perdidas w.r.t b2 (forma: ())</span></span>
<span id="cb140-13"><a href="#cb140-13" aria-hidden="true" tabindex="-1"></a>grad_b2 <span class="ot">&lt;-</span> grad_y_pred<span class="sc">$</span><span class="fu">sum</span>()</span>
<span id="cb140-14"><a href="#cb140-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb140-15"><a href="#cb140-15" aria-hidden="true" tabindex="-1"></a><span class="co"># gradiente de perdidas w.r.t w1 (dim 3 x 32)</span></span>
<span id="cb140-16"><a href="#cb140-16" aria-hidden="true" tabindex="-1"></a>grad_w1 <span class="ot">&lt;-</span> x<span class="sc">$</span><span class="fu">t</span>()<span class="sc">$</span><span class="fu">mm</span>(grad_h)</span>
<span id="cb140-17"><a href="#cb140-17" aria-hidden="true" tabindex="-1"></a><span class="co"># gradiente de perdidas w.r.t b1 (forma: (32, ))</span></span>
<span id="cb140-18"><a href="#cb140-18" aria-hidden="true" tabindex="-1"></a>grad_b1 <span class="ot">&lt;-</span> grad_h<span class="sc">$</span><span class="fu">sum</span>(<span class="at">dim =</span> <span class="dv">1</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>El ultimo paso es entonces usar los gradientes calculado para actualizar los pesos:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb141"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb141-1"><a href="#cb141-1" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="ot">&lt;-</span> <span class="fl">1e-4</span></span>
<span id="cb141-2"><a href="#cb141-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb141-3"><a href="#cb141-3" aria-hidden="true" tabindex="-1"></a>w2 <span class="ot">&lt;-</span> w2 <span class="sc">-</span> learning_rate <span class="sc">*</span> grad_w2</span>
<span id="cb141-4"><a href="#cb141-4" aria-hidden="true" tabindex="-1"></a>b2 <span class="ot">&lt;-</span> b2 <span class="sc">-</span> learning_rate <span class="sc">*</span> grad_b2</span>
<span id="cb141-5"><a href="#cb141-5" aria-hidden="true" tabindex="-1"></a>w1 <span class="ot">&lt;-</span> w1 <span class="sc">-</span> learning_rate <span class="sc">*</span> grad_w1</span>
<span id="cb141-6"><a href="#cb141-6" aria-hidden="true" tabindex="-1"></a>b1 <span class="ot">&lt;-</span> b1 <span class="sc">-</span> learning_rate <span class="sc">*</span> grad_b1</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Usando estos fragmentos de código podemos ahora llenar el formato anterior y hacer pruebas!</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb142"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb142-1"><a href="#cb142-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb142-2"><a href="#cb142-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb142-3"><a href="#cb142-3" aria-hidden="true" tabindex="-1"></a><span class="do">### generate training data -----------------------------------------------------</span></span>
<span id="cb142-4"><a href="#cb142-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb142-5"><a href="#cb142-5" aria-hidden="true" tabindex="-1"></a><span class="co"># input dimensionality (number of input features)</span></span>
<span id="cb142-6"><a href="#cb142-6" aria-hidden="true" tabindex="-1"></a>d_in <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb142-7"><a href="#cb142-7" aria-hidden="true" tabindex="-1"></a><span class="co"># output dimensionality (number of predicted features)</span></span>
<span id="cb142-8"><a href="#cb142-8" aria-hidden="true" tabindex="-1"></a>d_out <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb142-9"><a href="#cb142-9" aria-hidden="true" tabindex="-1"></a><span class="co"># number of observations in training set</span></span>
<span id="cb142-10"><a href="#cb142-10" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb142-11"><a href="#cb142-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb142-12"><a href="#cb142-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb142-13"><a href="#cb142-13" aria-hidden="true" tabindex="-1"></a><span class="co"># create random data</span></span>
<span id="cb142-14"><a href="#cb142-14" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">torch_randn</span>(n, d_in)</span>
<span id="cb142-15"><a href="#cb142-15" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span></span>
<span id="cb142-16"><a href="#cb142-16" aria-hidden="true" tabindex="-1"></a>  x[, <span class="dv">1</span>, <span class="cn">NULL</span>] <span class="sc">*</span> <span class="fl">0.2</span> <span class="sc">-</span> x[, <span class="dv">2</span>, <span class="cn">NULL</span>] <span class="sc">*</span> <span class="fl">1.3</span> <span class="sc">-</span> x[, <span class="dv">3</span>, <span class="cn">NULL</span>] <span class="sc">*</span> <span class="fl">0.5</span> <span class="sc">+</span> <span class="fu">torch_randn</span>(n, <span class="dv">1</span>)</span>
<span id="cb142-17"><a href="#cb142-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb142-18"><a href="#cb142-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb142-19"><a href="#cb142-19" aria-hidden="true" tabindex="-1"></a><span class="do">### initialize weights ---------------------------------------------------------</span></span>
<span id="cb142-20"><a href="#cb142-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb142-21"><a href="#cb142-21" aria-hidden="true" tabindex="-1"></a><span class="co"># dimensionality of hidden layer</span></span>
<span id="cb142-22"><a href="#cb142-22" aria-hidden="true" tabindex="-1"></a>d_hidden <span class="ot">&lt;-</span> <span class="dv">32</span></span>
<span id="cb142-23"><a href="#cb142-23" aria-hidden="true" tabindex="-1"></a><span class="co"># weights connecting input to hidden layer</span></span>
<span id="cb142-24"><a href="#cb142-24" aria-hidden="true" tabindex="-1"></a>w1 <span class="ot">&lt;-</span> <span class="fu">torch_randn</span>(d_in, d_hidden)</span>
<span id="cb142-25"><a href="#cb142-25" aria-hidden="true" tabindex="-1"></a><span class="co"># weights connecting hidden to output layer</span></span>
<span id="cb142-26"><a href="#cb142-26" aria-hidden="true" tabindex="-1"></a>w2 <span class="ot">&lt;-</span> <span class="fu">torch_randn</span>(d_hidden, d_out)</span>
<span id="cb142-27"><a href="#cb142-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb142-28"><a href="#cb142-28" aria-hidden="true" tabindex="-1"></a><span class="co"># hidden layer bias</span></span>
<span id="cb142-29"><a href="#cb142-29" aria-hidden="true" tabindex="-1"></a>b1 <span class="ot">&lt;-</span> <span class="fu">torch_zeros</span>(<span class="dv">1</span>, d_hidden)</span>
<span id="cb142-30"><a href="#cb142-30" aria-hidden="true" tabindex="-1"></a><span class="co"># output layer bias</span></span>
<span id="cb142-31"><a href="#cb142-31" aria-hidden="true" tabindex="-1"></a>b2 <span class="ot">&lt;-</span> <span class="fu">torch_zeros</span>(<span class="dv">1</span>, d_out)</span>
<span id="cb142-32"><a href="#cb142-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb142-33"><a href="#cb142-33" aria-hidden="true" tabindex="-1"></a><span class="do">### network parameters ---------------------------------------------------------</span></span>
<span id="cb142-34"><a href="#cb142-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb142-35"><a href="#cb142-35" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="ot">&lt;-</span> <span class="fl">1e-4</span></span>
<span id="cb142-36"><a href="#cb142-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb142-37"><a href="#cb142-37" aria-hidden="true" tabindex="-1"></a><span class="do">### training loop --------------------------------------------------------------</span></span>
<span id="cb142-38"><a href="#cb142-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb142-39"><a href="#cb142-39" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">200</span>) {</span>
<span id="cb142-40"><a href="#cb142-40" aria-hidden="true" tabindex="-1"></a>  <span class="do">### -------- Forward pass --------</span></span>
<span id="cb142-41"><a href="#cb142-41" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb142-42"><a href="#cb142-42" aria-hidden="true" tabindex="-1"></a>  <span class="co"># compute pre-activations of hidden layers (dim: 100 x 32)</span></span>
<span id="cb142-43"><a href="#cb142-43" aria-hidden="true" tabindex="-1"></a>  h <span class="ot">&lt;-</span> x<span class="sc">$</span><span class="fu">mm</span>(w1) <span class="sc">+</span> b1</span>
<span id="cb142-44"><a href="#cb142-44" aria-hidden="true" tabindex="-1"></a>  <span class="co"># apply activation function (dim: 100 x 32)</span></span>
<span id="cb142-45"><a href="#cb142-45" aria-hidden="true" tabindex="-1"></a>  h_relu <span class="ot">&lt;-</span> h<span class="sc">$</span><span class="fu">clamp</span>(<span class="at">min =</span> <span class="dv">0</span>)</span>
<span id="cb142-46"><a href="#cb142-46" aria-hidden="true" tabindex="-1"></a>  <span class="co"># compute output (dim: 100 x 1)</span></span>
<span id="cb142-47"><a href="#cb142-47" aria-hidden="true" tabindex="-1"></a>  y_pred <span class="ot">&lt;-</span> h_relu<span class="sc">$</span><span class="fu">mm</span>(w2) <span class="sc">+</span> b2</span>
<span id="cb142-48"><a href="#cb142-48" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb142-49"><a href="#cb142-49" aria-hidden="true" tabindex="-1"></a>  <span class="do">### -------- compute loss --------</span></span>
<span id="cb142-50"><a href="#cb142-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb142-51"><a href="#cb142-51" aria-hidden="true" tabindex="-1"></a>  loss <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>((y_pred <span class="sc">-</span> y)<span class="sc">$</span><span class="fu">pow</span>(<span class="dv">2</span>)<span class="sc">$</span><span class="fu">sum</span>())</span>
<span id="cb142-52"><a href="#cb142-52" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb142-53"><a href="#cb142-53" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (t <span class="sc">%%</span> <span class="dv">10</span> <span class="sc">==</span> <span class="dv">0</span>)</span>
<span id="cb142-54"><a href="#cb142-54" aria-hidden="true" tabindex="-1"></a>    <span class="fu">cat</span>(<span class="st">"Epoch: "</span>, t, <span class="st">"   Loss: "</span>, loss, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb142-55"><a href="#cb142-55" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb142-56"><a href="#cb142-56" aria-hidden="true" tabindex="-1"></a>  <span class="do">### -------- Backpropagation --------</span></span>
<span id="cb142-57"><a href="#cb142-57" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb142-58"><a href="#cb142-58" aria-hidden="true" tabindex="-1"></a>  <span class="co"># gradient of loss w.r.t. prediction (dim: 100 x 1)</span></span>
<span id="cb142-59"><a href="#cb142-59" aria-hidden="true" tabindex="-1"></a>  grad_y_pred <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> (y_pred <span class="sc">-</span> y)</span>
<span id="cb142-60"><a href="#cb142-60" aria-hidden="true" tabindex="-1"></a>  <span class="co"># gradient of loss w.r.t. w2 (dim: 32 x 1)</span></span>
<span id="cb142-61"><a href="#cb142-61" aria-hidden="true" tabindex="-1"></a>  grad_w2 <span class="ot">&lt;-</span> h_relu<span class="sc">$</span><span class="fu">t</span>()<span class="sc">$</span><span class="fu">mm</span>(grad_y_pred)</span>
<span id="cb142-62"><a href="#cb142-62" aria-hidden="true" tabindex="-1"></a>  <span class="co"># gradient of loss w.r.t. hidden activation (dim: 100 x 32)</span></span>
<span id="cb142-63"><a href="#cb142-63" aria-hidden="true" tabindex="-1"></a>  grad_h_relu <span class="ot">&lt;-</span> grad_y_pred<span class="sc">$</span><span class="fu">mm</span>(</span>
<span id="cb142-64"><a href="#cb142-64" aria-hidden="true" tabindex="-1"></a>    w2<span class="sc">$</span><span class="fu">t</span>())</span>
<span id="cb142-65"><a href="#cb142-65" aria-hidden="true" tabindex="-1"></a>  <span class="co"># gradient of loss w.r.t. hidden pre-activation (dim: 100 x 32)</span></span>
<span id="cb142-66"><a href="#cb142-66" aria-hidden="true" tabindex="-1"></a>  grad_h <span class="ot">&lt;-</span> grad_h_relu<span class="sc">$</span><span class="fu">clone</span>()</span>
<span id="cb142-67"><a href="#cb142-67" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb142-68"><a href="#cb142-68" aria-hidden="true" tabindex="-1"></a>  grad_h[h <span class="sc">&lt;</span> <span class="dv">0</span>] <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb142-69"><a href="#cb142-69" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb142-70"><a href="#cb142-70" aria-hidden="true" tabindex="-1"></a>  <span class="co"># gradient of loss w.r.t. b2 (shape: ())</span></span>
<span id="cb142-71"><a href="#cb142-71" aria-hidden="true" tabindex="-1"></a>  grad_b2 <span class="ot">&lt;-</span> grad_y_pred<span class="sc">$</span><span class="fu">sum</span>()</span>
<span id="cb142-72"><a href="#cb142-72" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb142-73"><a href="#cb142-73" aria-hidden="true" tabindex="-1"></a>  <span class="co"># gradient of loss w.r.t. w1 (dim: 3 x 32)</span></span>
<span id="cb142-74"><a href="#cb142-74" aria-hidden="true" tabindex="-1"></a>  grad_w1 <span class="ot">&lt;-</span> x<span class="sc">$</span><span class="fu">t</span>()<span class="sc">$</span><span class="fu">mm</span>(grad_h)</span>
<span id="cb142-75"><a href="#cb142-75" aria-hidden="true" tabindex="-1"></a>  <span class="co"># gradient of loss w.r.t. b1 (shape: (32, ))</span></span>
<span id="cb142-76"><a href="#cb142-76" aria-hidden="true" tabindex="-1"></a>  grad_b1 <span class="ot">&lt;-</span> grad_h<span class="sc">$</span><span class="fu">sum</span>(<span class="at">dim =</span> <span class="dv">1</span>)</span>
<span id="cb142-77"><a href="#cb142-77" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb142-78"><a href="#cb142-78" aria-hidden="true" tabindex="-1"></a>  <span class="do">### -------- Update weights --------</span></span>
<span id="cb142-79"><a href="#cb142-79" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb142-80"><a href="#cb142-80" aria-hidden="true" tabindex="-1"></a>  w2 <span class="ot">&lt;-</span> w2 <span class="sc">-</span> learning_rate <span class="sc">*</span> grad_w2</span>
<span id="cb142-81"><a href="#cb142-81" aria-hidden="true" tabindex="-1"></a>  b2 <span class="ot">&lt;-</span> b2 <span class="sc">-</span> learning_rate <span class="sc">*</span> grad_b2</span>
<span id="cb142-82"><a href="#cb142-82" aria-hidden="true" tabindex="-1"></a>  w1 <span class="ot">&lt;-</span> w1 <span class="sc">-</span> learning_rate <span class="sc">*</span> grad_w1</span>
<span id="cb142-83"><a href="#cb142-83" aria-hidden="true" tabindex="-1"></a>  b1 <span class="ot">&lt;-</span> b1 <span class="sc">-</span> learning_rate <span class="sc">*</span> grad_b1</span>
<span id="cb142-84"><a href="#cb142-84" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb142-85"><a href="#cb142-85" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch:  10    Loss:  239.8459 
Epoch:  20    Loss:  175.6584 
Epoch:  30    Loss:  142.8526 
Epoch:  40    Loss:  123.4776 
Epoch:  50    Loss:  110.2153 
Epoch:  60    Loss:  101.4229 
Epoch:  70    Loss:  95.29362 
Epoch:  80    Loss:  90.94321 
Epoch:  90    Loss:  87.41534 
Epoch:  100    Loss:  84.34146 
Epoch:  110    Loss:  81.86013 
Epoch:  120    Loss:  79.76909 
Epoch:  130    Loss:  77.94298 
Epoch:  140    Loss:  76.36224 
Epoch:  150    Loss:  74.9823 
Epoch:  160    Loss:  73.76436 
Epoch:  170    Loss:  72.68542 
Epoch:  180    Loss:  71.69421 
Epoch:  190    Loss:  70.77998 
Epoch:  200    Loss:  69.95052 </code></pre>
</div>
</div>
<p>Parece que funciona bastante bien! También se ha cumplido con el propósito inicial: mostrar todo lo que se puede conseguir usando únicamente tensores con <em>torch</em>. En caso que no te sientas entusiasmado con el desarrollo de la lógica de propagación hacia atrás, no te preocupes, en la próxima entrega esto será significativamente menos exigente. Nos veremos entonces!</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiado");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiado");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>