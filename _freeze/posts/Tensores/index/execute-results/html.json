{
  "hash": "a8d36837999494453ce6cb6cf93fe875",
  "result": {
    "markdown": "---\ntitle: \"Familiarizandose con tensores en torch\"\nauthor: \"Jhonatan Zambrano\"\ndate: \"2023-01-17\"\ncategories: [torch, tensores]\nabstract: \"Se presentan aquí las cosas principales que necesitas saber sobre los tensores de Torch. Como ejemplo ilustrativo se va a programar una red neuronal sencilla desde el principio.\"\nimage: \"tensor.png\"\nlang: \"es\"\n---\n\n\n![](tensor.png)\n\n\n\n\n\n## Introducción\n\nAnteriormente se introdujo **torch**, un paquete de R que provee funcionalidad nativa similar a la que tienen los usuarios de Python por medio de PyTorch. Allí se asumió algún conocimiento de Keras y TensorFlow. Por lo anterior, se \"retrató\" torch de forma que pudiera ser de ayuda para alguien que haya \"crecido\" con la forma en que se entrena un modelo en Keras : enfocándose en las diferencias, sin perder de vista el proceso completo.\n\nEn esta publicación se cambia de perspectiva. Se programa una red neuronal sencilla \"desde el principio\" haciendo uso únicamente de uno de los bloques constructivos básicos de torch: *tensores*. Esta red sera tan de \"bajo nivel\" como puede es posible. (Para aquellos menos inclinados a las matemáticas, esto puede servir como un repaso sobre que es lo que ocurre realmente detrás de todas las herramientas que han sido convenientemente construidas para nosotros. Pero el propósito real es ilustrar todo lo que se puede hacer únicamente con tensores).\n\nPosteriormente, se publicaran tres documentos que mostrarán progresivamente como se puede ir reduciendo el esfuerzo: notablemente desde el principio, enormemente una vez se hayan terminado. Al finalizar estas publicaciones habrás visto como la derivación automática funciona en torch, como usar módulos (capas, in el idioma de keras) y optimizadores. Para ese entonces, tendrás fuertes bases para ser usadas cuando se aplique torch al desarrollo de tareas del mundo real.\n\nEsta publicación será la mas extensa, dado que hay mucho por aprender acerca de los tensores: como crearlos, como manipular sus contenidos o modificas sus formas, como convertirlos en arreglos de R, matrices o vectores, y por supuesto, dada la omnipresente necesidad de velocidad, como ejecutar todas estas operaciones en la GPU. Una vez cumplida la agenda, programaremos la mencionada red neuronal, observando todos estos aspectos en acción.\n\n## Tensores\n\n### Creación\n\nLos tensores pueden ser creados especificando los valores individuales. aqui se crean dos tensores uni-dimensionales (vectores), de tipo \"float\" y \"bool\" respectivamente:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(torch)\n# un vector 1d de tamaño 2\nt <- torch_tensor(c(1, 2))\nt\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_tensor\n 1\n 2\n[ CPUFloatType{2} ]\n```\n:::\n\n```{.r .cell-code}\n# Ahora un vector 1d, pero del tipo bool\nt<-torch_tensor(c(TRUE, FALSE))\n```\n:::\n\n\nY aquí se presentan dos modos de crear tensores bi-dimensionales (matrices). Note como en el segundo modo se necesita especificar `byrow = TRUE` en el llamado a `matrix()`para obtener los valores ordenados en orden fila-mayor.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# un tensor de 3x3 (matriz)\nt <- torch_tensor(rbind(c(1, 2, 0), c(3, 0, 0), c(4, 5, 6)))\nt\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_tensor\n 1  2  0\n 3  0  0\n 4  5  6\n[ CPUFloatType{3,3} ]\n```\n:::\n\n```{.r .cell-code}\n# otro tensor de 3x3\nt <- torch_tensor(matrix(1:9, ncol = 3, byrow = T))\nt\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_tensor\n 1  2  3\n 4  5  6\n 7  8  9\n[ CPULongType{3,3} ]\n```\n:::\n:::\n\n\nPara dimensiones mas altas especialmente, puede se mas facil especificar el tipo de tensor de forma abstracta, como en: \"dame un tensor de \\<...\\> de la forma n1 x n2\" donde \\<...\\> puede ser \"ceros\", \"unos\", o por ejemplo, \"valores muestreados de una distribución normal estándar\":\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# un tensor de 3x3 de valores normalmente distribuidos\nt <- torch_randn(3, 3)\nt\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_tensor\n 1.6203 -0.7829 -0.7159\n 1.3453 -1.6175 -0.3454\n-1.6268 -0.2089 -0.2962\n[ CPUFloatType{3,3} ]\n```\n:::\n\n```{.r .cell-code}\n# un tensor de ceros de 4x2x2 (3d)\nt <- torch_zeros(4, 2, 2)\nt\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_tensor\n(1,.,.) = \n  0  0\n  0  0\n\n(2,.,.) = \n  0  0\n  0  0\n\n(3,.,.) = \n  0  0\n  0  0\n\n(4,.,.) = \n  0  0\n  0  0\n[ CPUFloatType{4,2,2} ]\n```\n:::\n:::\n\n\nExisten muchas funciones similares, incluidas: `torch_arange()` para crear un tensor que mantiene una secuencia de valores igualmente espaciados, `torch_eye()` el cual retorna una matriz identidad y `torch_logspace()` que llena un rango especifico con una lista de valores espaciados logarítmicamente.\n\nSi el argumento `dtype` no se especifica, `torch` inferirá el tipo de datos de los valores entregados. Por ejemplo:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt <- torch_tensor(c(3, 5, 7))\nt$dtype\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_Float\n```\n:::\n\n```{.r .cell-code}\nt <- torch_tensor(1L)\nt$dtype\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_Long\n```\n:::\n:::\n\n\nPero se puede definir explícitamente un `dtype` diferente si se desea:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt <- torch_tensor(1, dtype = torch_double())\nt$dtype\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_Double\n```\n:::\n:::\n\n\nLos tensores de `torch` residen en un *dispositivo*. Por defecto, será en la CPU:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt$device\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_device(type='cpu')\n```\n:::\n:::\n\n\nAunque se puede definir un tensor que resida en la GPU:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt <- torch_tensor(2, device = \"cuda\")\nt$device\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_device(type='cuda', index=0)\n```\n:::\n:::\n\n\nSe hablará mas sobre los dispositivos mas adelante.\n\nHay otro parámetro importante en las funciones para creación de tensores: `requires_grad`. Sin embargo, aquí debemos apelar a la paciencia, este tema sera discutido de forma prominente en la siguiente publicación.\n\n### Conversión a tipos de datos nativos de R\n\nPara convertir tensores `torch` a datos nativos de R se usa la función `as_array()`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt <- torch_tensor(matrix(1:9, ncol = 3, byrow = TRUE))\nas.array(t)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n[3,]    7    8    9\n```\n:::\n:::\n\n\nDependiente de si el tensor es de una, dos o tres dimensiones, el objeto resultante nativo será un vector, una matriz o un arreglo:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt <- torch_tensor(c(1, 2, 3))\nas.array(t) %>% class()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"numeric\"\n```\n:::\n\n```{.r .cell-code}\nt <- torch_ones(c(2, 2))\nas.array(t) %>% class()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"matrix\" \"array\" \n```\n:::\n\n```{.r .cell-code}\nt <- torch_ones(c(2, 2, 2))\nas.array(t) %>% class()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"array\"\n```\n:::\n:::\n\n\nPara tensores de una o dos dimensiones, también es posible usar `as.integer()` o `as.matrix()`.\n\nSi un tensor actualmente reside en la GPU, se requiere moverlo a la CPU primero:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt <- torch_tensor(2, device = \"cuda\")\nas.integer(t$cpu())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2\n```\n:::\n:::\n\n\n### Indexado y seccionado de tensores\n\nA menudo se desea obtener solo una parte de un tensor, incluso un único valor. En estos casos se habla de *seccionado* e *indexado* respectivamente.\n\nEn R, estas operaciones son *base-1* es decir, la primera posición de cualquier arreglo se identifica con el número 1 y no con el número 0. El mismo comportamiento fue implementado para `torch`. De este modo, muchas de la funcionalidad descrita en esta sección se podría sentir intuitiva.\n\n### La parte similar a R\n\nNada de lo siguiente debería parecer demasiado sorpresivo:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt <- torch_tensor(rbind(c(1, 2, 3), c(4, 5, 6)))\nt\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_tensor\n 1  2  3\n 4  5  6\n[ CPUFloatType{2,3} ]\n```\n:::\n\n```{.r .cell-code}\n# Un unico valor\nt[1, 1]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_tensor\n1\n[ CPUFloatType{} ]\n```\n:::\n\n```{.r .cell-code}\n# primera fila, todas las columnas\nt[1, ]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_tensor\n 1\n 2\n 3\n[ CPUFloatType{3} ]\n```\n:::\n\n```{.r .cell-code}\n# primera fila, un subconjunto de columnas\nt[1, 1:2]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_tensor\n 1\n 2\n[ CPUFloatType{2} ]\n```\n:::\n:::\n\n\nNótese como, tal y como ocurre en R, las dimensiones son eliminadas\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt <- torch_tensor(rbind(c(1, 2, 3), c(4, 5, 6)))\n\n# 2x3\nt$size()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2 3\n```\n:::\n\n```{.r .cell-code}\n# Una sola fila: sera devuelto como un vector\nt[1, 1:2]$size()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2\n```\n:::\n\n```{.r .cell-code}\n# Un solo elemento\nt[1, 1]$size()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ninteger(0)\n```\n:::\n:::\n\n\nY al igual que en R, se pueden mantener las dimensiones originales si se especifica `drop = FALSE`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt[1, 1:2, drop = F]$size()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1 2\n```\n:::\n\n```{.r .cell-code}\nt[1, 1, drop = F]$size()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1 1\n```\n:::\n:::\n\n\n### La parte distinta a R\n\nR usa números negativos para remover elementos en posiciones especificas, en `torch` los números negativos indican que se inicia contando desde el final de un tensor, siendo -1 el último elemento:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt <- torch_tensor(rbind(c(1, 2, 3), c(4, 5, 6)))\n\nt[1, -1]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_tensor\n3\n[ CPUFloatType{} ]\n```\n:::\n\n```{.r .cell-code}\nt[ , -2:-1]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_tensor\n 2  3\n 5  6\n[ CPUFloatType{2,2} ]\n```\n:::\n:::\n\n\nEsta característica puede ser conocida de NumPy. Al igual que la siguiente:\n\nCuando la expresión de rebanado `m:n` se aumenta con un tercer numero `m:n:o` se tomará cada o-ésimo ítem del rango especificado por m y n:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt <- torch_tensor(1:10)\nt[2:10:2]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_tensor\n  2\n  4\n  6\n  8\n 10\n[ CPULongType{5} ]\n```\n:::\n:::\n\n\nAlgunas veces no se sabe cuantas dimensiones tiene un tensor, pero sí sabemos que hacer con la última dimensión, o la primera. Para obviar todas las otras podemos usar:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt <- torch_randint(-7, 7, size = c(2, 2, 2))\nt\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_tensor\n(1,.,.) = \n  5  5\n  1 -1\n\n(2,.,.) = \n -1 -2\n  4  5\n[ CPUFloatType{2,2,2} ]\n```\n:::\n\n```{.r .cell-code}\nt[.., 1]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_tensor\n 5  1\n-1  4\n[ CPUFloatType{2,2} ]\n```\n:::\n\n```{.r .cell-code}\nt[2, ..]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_tensor\n-1 -2\n 4  5\n[ CPUFloatType{2,2} ]\n```\n:::\n:::\n\n\nPasamos ahora a un tema que, en la practica, es tan indispensable como el seccionamiento: cambios en la forma de los tensores.\n\n### Cambiando la forma de los tensores\n\nLoa cambios en las formas de los tensores pueden ocurrir de dos formas fundamentalmente. Observando lo que el \"reformado\" es realmente: *mantener los valores pero modifica el arreglo*, podríamos ya sea, alterar como los valores están distribuidos físicamente, o mantener a estructura física como está y solo cambiar el \"mapeo\", es decir, un cambio semántico.\n\nEn el primer caso, se debe apartar almacenamiento para dos tensores, la fuente y el destino, los elementos serán copiados del último al primero. En el segundo caso, físicamente solo habrá un tensor, referenciado por dos entidades lógicas con distintos metadatos.\n\nNo es de sorprenderse que por razones de rendimiento, sean preferidas las operaciones del segundo caso.\n\n#### Reformado copia cero\n\nEmpezamos con métodos de copia cero, dado que serán usados siempre que podamos.\n\nUn caso especial a menudo visto en la practica es adicionar o remover dimensiones con un solo elemento.\n\n`unsqueeze()` adiciona una dimensión de tamaño 1 a la posición especificada por `dim`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt1 <- torch_randint(low = 3, high = 7, size = c(3, 3, 3))\nt1$size()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 3 3 3\n```\n:::\n\n```{.r .cell-code}\nt2 <- t1$unsqueeze(dim = 1)\nt2$size()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1 3 3 3\n```\n:::\n\n```{.r .cell-code}\nt3 <- t1$unsqueeze(dim = 2)\nt3$size()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 3 1 3 3\n```\n:::\n:::\n\n\nPor otro lado, `squeeze` remueve las dimensiones de tamaño 1:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt4 <- t3$squeeze()\nt4$size()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 3 3 3\n```\n:::\n:::\n\n\nLo mismo puede conseguirse con `view()`, sin embargo, esta función es mucho mas general, aquí se permite reformar los datos a cualquier dimensionalidad válida (es decir que el número de elementos se mantiene igual).\n\nA continuación tenemos un tensor 3x2 que se reforma a una de tamaño 2x3:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt1 <- torch_tensor(rbind(c(1, 2), c(3, 4), c(5, 6)))\nt1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_tensor\n 1  2\n 3  4\n 5  6\n[ CPUFloatType{3,2} ]\n```\n:::\n\n```{.r .cell-code}\nt2 <- t1$view(c(2, 3))\nt2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_tensor\n 1  2  3\n 4  5  6\n[ CPUFloatType{2,3} ]\n```\n:::\n:::\n\n\nNótese que esto es diferente a transponer la matriz\n\nEn lugar de ir de 2 a 3 dimensiones, podemos \"aplanar\" una matriz a un vector.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt4 <- t1$view(c(-1, 6))\n\nt4$size()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1 6\n```\n:::\n\n```{.r .cell-code}\nt4\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_tensor\n 1  2  3  4  5  6\n[ CPUFloatType{1,6} ]\n```\n:::\n:::\n\n\nEn contraste con las operaciones de indexación, aqui no se pierde dimensiones.\n\nComo se dijo anteriormente, las operaciones `squeeze()` o `view()` no crea copias. O dicho de otro modo: el tensor de salida comparte el almacenamineto con el tensor de entrada. Este hecho se puede verificar del siguiente modo:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt1$storage()$data_ptr()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"0x556940983e40\"\n```\n:::\n\n```{.r .cell-code}\nt2$storage()$data_ptr()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"0x556940983e40\"\n```\n:::\n:::\n\n\nLo que difiere es los metadatos que `torch` mantiene acerca de los dos tensores. Aqui la información relevante es el *paso*:\n\nEl método `stride()` (*paso*) de un tensor revisa, para cada dimensión, cuantos elementos tienen que ser atravesados para llegar a su próximo elemento (fila o columna, en dos dimensiones). Para `t1`, de forma 3x2, tenemos que saltar sobre 2 elementos para llegar a la siguiente fila. Para llegar a la siguiente columna, solo tendríamos que saltar sobre un elemento:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt1$stride()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2 1\n```\n:::\n:::\n\n\nPara `t2`, de la forma 3x2, la distancia entre los elementos columna es el mismo, pero la distancia entre filas es ahora 3:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt2$stride()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 3 1\n```\n:::\n:::\n\n\nMientras que las operaciones \"cero-copia\" son óptimas, hay casos donde no sirven.\n\nCon `view()`, puede ocurrir cuando un tensor obtenido vía una operación (diferente a `view`) que previamente haya modificado el *stride o paso*. Un ejemplo puede ser `transpose()`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt1 <- torch_tensor(rbind(c(1, 2), c(3, 4), c(5, 6)))\nt1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_tensor\n 1  2\n 3  4\n 5  6\n[ CPUFloatType{3,2} ]\n```\n:::\n\n```{.r .cell-code}\nt1$stride()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2 1\n```\n:::\n\n```{.r .cell-code}\nt2 <- t1$t()\nt2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_tensor\n 1  3  5\n 2  4  6\n[ CPUFloatType{2,3} ]\n```\n:::\n\n```{.r .cell-code}\nt2$stride()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1 2\n```\n:::\n:::\n\n\nEn el lenguaje de `torch`, los tensores (como `t2`) que están reutilizando cosas almacenadas previamente (solo que leídas de forma distinta), se dice que no son contiguas. Un modo de reformarlos es usar la función `contiguous()` previamente. Esto lo veremos en la siguiente sección.\n\n#### Reformado con copia\n\nEn el siguiente fragmento de codigo se falla al intentar reformar t2 usando `view()`, dado que el tensor ya contiene información que indica que los datos no deben ser leidos en su orden fisico.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt1 <- torch_tensor(rbind(c(1, 2), c(3, 4), c(5, 6)))\n\nt2 <- t1$t()\n\nt2$view(6)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in (function (self, size) : view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\nException raised from view_impl at ../aten/src/ATen/native/TensorShape.cpp:2674 (most recent call first):\nframe #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x6b (0x7f384d8452eb in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libc10.so)\nframe #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0xd1 (0x7f384d840e41 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libc10.so)\nframe #2: at::native::view(at::Tensor const&, c10::ArrayRef<long>) + 0x325 (0x7f3820bad305 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)\nframe #3: <unknown function> + 0x200b006 (0x7f382140b006 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)\nframe #4: at::_ops::view::redispatch(c10::DispatchKeySet, at::Tensor const&, c10::ArrayRef<long>) + 0x98 (0x7f3821275718 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)\nframe #5: <unknown function> + 0x37902f5 (0x7f3822b902f5 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)\nframe #6: <unknown function> + 0x3790699 (0x7f3822b90699 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)\nframe #7: at::_ops::view::redispatch(c10::DispatchKeySet, at::Tensor const&, c10::ArrayRef<long>) + 0x98 (0x7f3821275718 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)\nframe #8: <unknown function> + 0x32b4588 (0x7f38226b4588 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)\nframe #9: <unknown function> + 0x32b4a69 (0x7f38226b4a69 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)\nframe #10: at::_ops::view::call(at::Tensor const&, c10::ArrayRef<long>) + 0xe7 (0x7f38212a1327 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)\nframe #11: at::Tensor::view(c10::ArrayRef<long>) const + 0x42 (0x7f384e6050ce in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/liblantern.so)\nframe #12: _lantern_Tensor_view_tensor_intarrayref + 0x130 (0x7f384e3cf96d in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/liblantern.so)\nframe #13: cpp_torch_method_view_self_Tensor_size_IntArrayRef(XPtrTorchTensor, XPtrTorchIntArrayRef) + 0x35 (0x7f3851c2ff65 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/libs/torchpkg.so)\nframe #14: _torch_cpp_torch_method_view_self_Tensor_size_IntArrayRef + 0xa1 (0x7f3851996221 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/libs/torchpkg.so)\nframe #15: <unknown function> + 0xf7b6c (0x7f385caf7b6c in /usr/lib/R/lib/libR.so)\nframe #16: <unknown function> + 0xf80fd (0x7f385caf80fd in /usr/lib/R/lib/libR.so)\nframe #17: <unknown function> + 0x1317b5 (0x7f385cb317b5 in /usr/lib/R/lib/libR.so)\nframe #18: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)\nframe #19: <unknown function> + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)\nframe #20: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)\nframe #21: Rf_eval + 0x2ac (0x7f385cb4ea1c in /usr/lib/R/lib/libR.so)\nframe #22: <unknown function> + 0xc3227 (0x7f385cac3227 in /usr/lib/R/lib/libR.so)\nframe #23: <unknown function> + 0x1317b5 (0x7f385cb317b5 in /usr/lib/R/lib/libR.so)\nframe #24: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)\nframe #25: <unknown function> + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)\nframe #26: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)\nframe #27: <unknown function> + 0x13ea30 (0x7f385cb3ea30 in /usr/lib/R/lib/libR.so)\nframe #28: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)\nframe #29: <unknown function> + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)\nframe #30: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)\nframe #31: <unknown function> + 0x13ea30 (0x7f385cb3ea30 in /usr/lib/R/lib/libR.so)\nframe #32: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)\nframe #33: <unknown function> + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)\nframe #34: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)\nframe #35: <unknown function> + 0x13ea30 (0x7f385cb3ea30 in /usr/lib/R/lib/libR.so)\nframe #36: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)\nframe #37: <unknown function> + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)\nframe #38: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)\nframe #39: <unknown function> + 0x13ea30 (0x7f385cb3ea30 in /usr/lib/R/lib/libR.so)\nframe #40: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)\nframe #41: <unknown function> + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)\nframe #42: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)\nframe #43: <unknown function> + 0x13ea30 (0x7f385cb3ea30 in /usr/lib/R/lib/libR.so)\nframe #44: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)\nframe #45: <unknown function> + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)\nframe #46: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)\nframe #47: <unknown function> + 0x13ea30 (0x7f385cb3ea30 in /usr/lib/R/lib/libR.so)\nframe #48: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)\nframe #49: <unknown function> + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)\nframe #50: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)\nframe #51: Rf_eval + 0x2ac (0x7f385cb4ea1c in /usr/lib/R/lib/libR.so)\nframe #52: <unknown function> + 0x153fa7 (0x7f385cb53fa7 in /usr/lib/R/lib/libR.so)\nframe #53: <unknown function> + 0x1317b5 (0x7f385cb317b5 in /usr/lib/R/lib/libR.so)\nframe #54: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)\nframe #55: <unknown function> + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)\nframe #56: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)\nframe #57: <unknown function> + 0x13ea30 (0x7f385cb3ea30 in /usr/lib/R/lib/libR.so)\nframe #58: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)\nframe #59: <unknown function> + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)\nframe #60: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)\nframe #61: <unknown function> + 0x13ea30 (0x7f385cb3ea30 in /usr/lib/R/lib/libR.so)\nframe #62: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)\nframe #63: <unknown function> + 0x14f294 (0x7f385cb4f294 in /usr/lib/R/lib/libR.so)\n```\n:::\n:::\n\n\nSin embargo, si primero llamamos `contiguous()`, un nuevo tensor es creado, el cual podra ser (virtualmente) reformado usando `view()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt3 <- t2$contiguous()\n\nt3$view(6)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_tensor\n 1\n 3\n 5\n 2\n 4\n 6\n[ CPUFloatType{6} ]\n```\n:::\n:::\n\n\nAlternativamente, podemos usar `reshape()`. Esta función se comportará similar a `view()` siempre que sea posible; de otro modo creará una copia física.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt2$storage()$data_ptr()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"0x556945ddf9c0\"\n```\n:::\n\n```{.r .cell-code}\nt4 <- t2$reshape(6)\n\nt2$storage()$data_ptr()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"0x556945ddf9c0\"\n```\n:::\n:::\n\n\n### Operaciones con tensores\n\nNo es para sorprenderse que `torch` provea una cantidad de operaciones con tensores; veremos algunos de ellos en el código de la red que se desarrollará luego y se encontrarán muchos mas con el uso de `torch`. Aquí echaremos un vistazo general a la semántica de los métodos de los tensores.\n\nLos métodos de los tensores normalmente retornan referencias a nuevos objetos. A continuación se suma a `t1` un clon de si mismo:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt1 <- torch_tensor(rbind(c(1, 2), c(3, 4), c(5, 6)))\nt2 <- t1$clone()\n\nt1$add(t2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_tensor\n  2   4\n  6   8\n 10  12\n[ CPUFloatType{3,2} ]\n```\n:::\n:::\n\n\nEn este proceso, `t1` no ha sido modificado:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_tensor\n 1  2\n 3  4\n 5  6\n[ CPUFloatType{3,2} ]\n```\n:::\n:::\n\n\nMuchos métodos tienen variantes para operaciones de \"mutación\". Todas estas incluyen un guion bajo:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt1$add_(t1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_tensor\n  2   4\n  6   8\n 10  12\n[ CPUFloatType{3,2} ]\n```\n:::\n\n```{.r .cell-code}\n# Esta vez t1 es modificado\nt1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_tensor\n  2   4\n  6   8\n 10  12\n[ CPUFloatType{3,2} ]\n```\n:::\n:::\n\n\nAlternativamente, se puede asignar el nuevo objeto a una nueva referencia de variable:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt3 <- t1$add(t1)\n\nt3\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_tensor\n  4   8\n 12  16\n 20  24\n[ CPUFloatType{3,2} ]\n```\n:::\n:::\n\n\nTenemos ahora una cosa que discutir antes de cerrar esta introducción a los tensores: ¿Como podemos ejecutar todas estas operaciones en la GPU?\n\n### Ejecutando en la GPU\n\nPara verificar si hay una GPU visible para `torch`, ejecutar:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncuda_is_available()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n\n```{.r .cell-code}\ncuda_device_count()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1\n```\n:::\n:::\n\n\nLos tensores pueden ser almacenado en la GPU directamente desde su creación\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndevice <- torch_device(\"cuda\")\n\nt <- torch_ones(c(2, 2), device = device)\n```\n:::\n\n\nTambién pueden ser movidos entre dispositivos en cualquier momento:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt2 <- t$cuda()\nt2$device\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_device(type='cuda', index=0)\n```\n:::\n\n```{.r .cell-code}\nt3 <- t2$cpu()\nt3$device\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_device(type='cpu')\n```\n:::\n:::\n\n\nEstamos por concluir la discusión sobre tensores. Hay una característica mas de `torch` que, a pesar de estar relacionada con operaciones con tensores, merece una mención especial. Es conocida como broadcasting (difusión).\n\n### Broadcasting\n\nA menudo ejecutamos operaciones en tensores cuyas formas no concuerdan con exactitud.\n\nPor ejemplo, podemos sumar un escalar con un tensor:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt1 <- torch_randn(c(3, 5))\n\nt1+22\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_tensor\n 23.3398  22.0977  21.5262  22.2440  20.0809\n 22.2100  21.8822  23.0445  21.1448  22.8481\n 22.9730  20.9074  22.9415  21.9149  21.4249\n[ CPUFloatType{3,5} ]\n```\n:::\n:::\n\n\nTambién funciona si sumamos un tensor de tamaño 1\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt1 + torch_tensor(c(22))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_tensor\n 23.3398  22.0977  21.5262  22.2440  20.0809\n 22.2100  21.8822  23.0445  21.1448  22.8481\n 22.9730  20.9074  22.9415  21.9149  21.4249\n[ CPUFloatType{3,5} ]\n```\n:::\n:::\n\n\nla suma de tensores de diferentes tamaños normalmente no funcionan:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt1 <- torch_randn(c(3, 5))\nt2 <- torch_randn(c(5, 5))\n\nt1$add(t2)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in (function (self, other, alpha) : The size of tensor a (3) must match the size of tensor b (5) at non-singleton dimension 0\nException raised from infer_size_impl at ../aten/src/ATen/ExpandUtils.cpp:35 (most recent call first):\nframe #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x6b (0x7f384d8452eb in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libc10.so)\nframe #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0xce (0x7f384d840cbe in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libc10.so)\nframe #2: at::infer_size_dimvector(c10::ArrayRef<long>, c10::ArrayRef<long>) + 0x48b (0x7f382061e32b in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)\nframe #3: at::TensorIteratorBase::compute_shape(at::TensorIteratorConfig const&) + 0x10d (0x7f38206713cd in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)\nframe #4: at::TensorIteratorBase::build(at::TensorIteratorConfig&) + 0x69 (0x7f3820672609 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)\nframe #5: at::TensorIteratorBase::build_borrowing_binary_op(at::TensorBase const&, at::TensorBase const&, at::TensorBase const&) + 0xf7 (0x7f3820673de7 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)\nframe #6: at::meta::structured_add_Tensor::meta(at::Tensor const&, at::Tensor const&, c10::Scalar const&) + 0x2f (0x7f382084183f in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)\nframe #7: <unknown function> + 0x20415e6 (0x7f38214415e6 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)\nframe #8: <unknown function> + 0x20416e6 (0x7f38214416e6 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)\nframe #9: at::_ops::add_Tensor::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&, c10::Scalar const&) + 0x98 (0x7f3821148cf8 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)\nframe #10: <unknown function> + 0x319a8ca (0x7f382259a8ca in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)\nframe #11: <unknown function> + 0x319b049 (0x7f382259b049 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)\nframe #12: at::_ops::add_Tensor::call(at::Tensor const&, at::Tensor const&, c10::Scalar const&) + 0x173 (0x7f3821177cc3 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/./libtorch_cpu.so)\nframe #13: at::Tensor::add(at::Tensor const&, c10::Scalar const&) const + 0x3f (0x7f384e5fc0ef in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/liblantern.so)\nframe #14: _lantern_Tensor_add_tensor_tensor_scalar + 0x13f (0x7f384e173b3b in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/lib/liblantern.so)\nframe #15: cpp_torch_method_add_self_Tensor_other_Tensor(XPtrTorchTensor, XPtrTorchTensor, XPtrTorchScalar) + 0x3b (0x7f3851c4fedb in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/libs/torchpkg.so)\nframe #16: _torch_cpp_torch_method_add_self_Tensor_other_Tensor + 0xb9 (0x7f3851945d99 in /home/jhonatan/R/x86_64-pc-linux-gnu-library/4.1/torch/libs/torchpkg.so)\nframe #17: <unknown function> + 0xf7b50 (0x7f385caf7b50 in /usr/lib/R/lib/libR.so)\nframe #18: <unknown function> + 0xf80fd (0x7f385caf80fd in /usr/lib/R/lib/libR.so)\nframe #19: <unknown function> + 0x1317b5 (0x7f385cb317b5 in /usr/lib/R/lib/libR.so)\nframe #20: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)\nframe #21: <unknown function> + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)\nframe #22: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)\nframe #23: Rf_eval + 0x2ac (0x7f385cb4ea1c in /usr/lib/R/lib/libR.so)\nframe #24: <unknown function> + 0xc3227 (0x7f385cac3227 in /usr/lib/R/lib/libR.so)\nframe #25: <unknown function> + 0x1317b5 (0x7f385cb317b5 in /usr/lib/R/lib/libR.so)\nframe #26: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)\nframe #27: <unknown function> + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)\nframe #28: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)\nframe #29: <unknown function> + 0x13ea30 (0x7f385cb3ea30 in /usr/lib/R/lib/libR.so)\nframe #30: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)\nframe #31: <unknown function> + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)\nframe #32: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)\nframe #33: <unknown function> + 0x13ea30 (0x7f385cb3ea30 in /usr/lib/R/lib/libR.so)\nframe #34: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)\nframe #35: <unknown function> + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)\nframe #36: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)\nframe #37: <unknown function> + 0x13ea30 (0x7f385cb3ea30 in /usr/lib/R/lib/libR.so)\nframe #38: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)\nframe #39: <unknown function> + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)\nframe #40: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)\nframe #41: <unknown function> + 0x13ea30 (0x7f385cb3ea30 in /usr/lib/R/lib/libR.so)\nframe #42: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)\nframe #43: <unknown function> + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)\nframe #44: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)\nframe #45: Rf_eval + 0x2ac (0x7f385cb4ea1c in /usr/lib/R/lib/libR.so)\nframe #46: <unknown function> + 0x153fa7 (0x7f385cb53fa7 in /usr/lib/R/lib/libR.so)\nframe #47: <unknown function> + 0x1317b5 (0x7f385cb317b5 in /usr/lib/R/lib/libR.so)\nframe #48: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)\nframe #49: <unknown function> + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)\nframe #50: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)\nframe #51: <unknown function> + 0x13ea30 (0x7f385cb3ea30 in /usr/lib/R/lib/libR.so)\nframe #52: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)\nframe #53: <unknown function> + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)\nframe #54: Rf_applyClosure + 0x1a5 (0x7f385cb512d5 in /usr/lib/R/lib/libR.so)\nframe #55: <unknown function> + 0x13ea30 (0x7f385cb3ea30 in /usr/lib/R/lib/libR.so)\nframe #56: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)\nframe #57: <unknown function> + 0x14f294 (0x7f385cb4f294 in /usr/lib/R/lib/libR.so)\nframe #58: Rf_eval + 0x39e (0x7f385cb4eb0e in /usr/lib/R/lib/libR.so)\nframe #59: <unknown function> + 0x1547c0 (0x7f385cb547c0 in /usr/lib/R/lib/libR.so)\nframe #60: <unknown function> + 0x192f17 (0x7f385cb92f17 in /usr/lib/R/lib/libR.so)\nframe #61: <unknown function> + 0x130cc8 (0x7f385cb30cc8 in /usr/lib/R/lib/libR.so)\nframe #62: Rf_eval + 0x180 (0x7f385cb4e8f0 in /usr/lib/R/lib/libR.so)\nframe #63: <unknown function> + 0x15048f (0x7f385cb5048f in /usr/lib/R/lib/libR.so)\n```\n:::\n:::\n\n\nSin embargo, bajo ciertas condiciones, uno o los dos tensores pueden ser expandidos virtualmente de forma que se alinean. Este comportamiento es lo que se denomina *broadcasting*. La forma en que esto funciona en `torch` no solo se inspira en NumPy, es idéntica.\n\nLas reglas son las siguientes:\n\n1.  Se alinean las formas de los arreglos empezando desde la derecha: Digamos que se tienen dos tensores, uno de la forma 8x1x6x1 y otro de 7x1x5:\n\nforma t1: 8 1 6 1 forma t2: 7 1 5\n\n2.  Mirando desde la derecha, los tamaños a lo largo de los ejes alineados: o son iguales o uno de ellos es igual a 1, en cuyo caso el ultimo es ampliado al tamaño del mayor. En nuestro ejemplo tendríamos:\n\nforma t1: 8 1 6 1 forma t2: 7 6 5\n\nCon el broadcasting ocurriendo en t2.\n\n3.  Si en el lado izquierdo, uno de los arreglos tiene un eje adicional (o mas de uno) el otro arreglo es virtualmente expandido para tener un tamaño de 1 es ese eje.\n\nforma t1: 8 1 6 1 forma t2: 1 7 1 5\n\ny luego ocurre el broadcast:\n\nforma t1: 8 1 6 1 forma t2: 8 7 1 5\n\nDe acuerdo con las anteriores reglas el ejemplo de sumar dos tensores de formas: 3x5 y 5x5 se podría modificar para permitir la suma de dos tensores.\n\nPor ejemplo, si t2 fuera 1x5, solo se requeriría ampliar a una forma de 3x5 antes de la operación suma:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt1 <- torch_randn(c(3, 5))\nt2 <- torch_randn(c(1, 5))\n\nt1$add(t2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_tensor\n 1.2613 -1.5797 -0.1304  0.8364  1.4811\n 2.0772 -0.5352 -0.1203 -0.3383  2.0498\n 3.3027 -1.4875 -0.3475 -0.1763  1.0905\n[ CPUFloatType{3,5} ]\n```\n:::\n:::\n\n\nSi fuera de tamaño 5, una dimensión antecesora virtual podría ser añadida y entonces, el mismo broadcasting podría tomar lugar como en el caso anterior.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt1 <- torch_randn(c(3, 5))\nt2 <- torch_randn(c(5))\n\nt1$add(t2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_tensor\n 0.6716  0.7809 -0.6019 -0.6897 -0.2175\n-2.2945  2.2061 -2.8415  3.0838 -1.1119\n 0.0464 -0.0846  0.1769  0.8541 -0.1863\n[ CPUFloatType{3,5} ]\n```\n:::\n:::\n\n\nA continuación un ejemplo mas complejo. Como ocurre un broadcasting en t1 y t2:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt1 <- torch_randn(c(1, 5))\nt2 <- torch_randn(c(3, 1))\n\nt1$add(t2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_tensor\n 0.3926 -0.4045 -0.5845 -1.5759  0.9646\n 0.0973 -0.6997 -0.8798 -1.8711  0.6694\n 1.8763  1.0792  0.8991 -0.0922  2.4483\n[ CPUFloatType{3,5} ]\n```\n:::\n:::\n\n\nComo ejemplo conclusivo, un producto exterior se puede computar a traves de broadcasting como sigue:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt1 <- torch_tensor(c(0, 10, 20, 30))\nt2 <- torch_tensor(c(1, 2, 3))\n\nt1$view(c(4, 1)) * t2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch_tensor\n  0   0   0\n 10  20  30\n 20  40  60\n 30  60  90\n[ CPUFloatType{4,3} ]\n```\n:::\n:::\n\n\nAhora si, estamos listos para implementar una red neuronal!\n\n## Red Neuronal Simple Usando Tensores\n\nNuestra tarea, para la cual sera usado una aproximación de bajo nivel y que será simplificada considerablemente en próximos desarrollos, consiste en hacer la regresión de una variable de salida basados en tres variables de entrada.\n\nSe usa *torch* directamente para simular algunos datos.\n\n### Datos\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# dimensión de la entrada\nd_in <- 3\n# dimensión de la salida\nd_out <- 1\n# cantidad de observaciones en el conjunto de entrenamiento\nn <- 100\n\n# Creación de datos aleatorios\n# Entrada\nx <- torch_randn(n, d_in)\n# Salida\ny <- x[, 1, drop = F] * 0.2 -\n  x[, 2, drop = F] * 1.3 -\n  x[, 3, drop = F] * 0.5 +\n  torch_randn(n, 1)\n```\n:::\n\n\nAhora, se requiere inicializar los pesos de la red. Tendremos una capa oculta con 32 unidades. El tamaño de la capa de salida, determinada por la tarea, es igual a 1.\n\n### Inicializar Pesos\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# dimensiones del la capa oculta\nd_hidden <- 32\n\n# Pesos que conectan la entrada con la capa oculta\nw1 <- torch_randn(d_in, d_hidden)\n# Pesos que conectan la capa oculta con la salida\nw2 <- torch_randn(d_hidden, d_out)\n\n# sesgos de la capa oculta\nb1 <- torch_zeros(1, d_hidden)\n# sesgos de la salida\nb2 <- torch_zeros(1, d_out)\n```\n:::\n\n\nAhora vamos a hacer el ciclo de entrenamiento propiamente. El ciclo de entrenamiento es, en realidad, la red neuronal.\n\n### Ciclo de entrenamiento\n\nEn cada iteración (época), el ciclo de entrenamiento hace cuatro cosas:\n\n-   Se hace la propagación hacia adelante, se computa las predicciones\n-   Se comparan las predicciones con las salidas reales y se cuantifica la perdida\n-   se hace la propagación hacia atrás en la red, se calculan los gradientes que indican como deben cambiarse los pesos\n-   Se actualizan los pesos, haciendo uso de la tasa de aprendizaje.\n\nEl formato seria como se muestra a continuación:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfor (t in 1:200) {\n  ### -------------- Propagación hacia adelante ---------------\n  # Aquí vamos a calcular la predicción\n  \n  \n  ### -------------- Calculo de la perdida --------------------\n  # Aquí vamos a calcular la suma de los errores al cuadrado\n  \n  \n  ### -------------- Propagación hacia atrás ------------------\n  # Aquí vamos a propagar hacia atrás para calcular los gradientes\n  \n  \n  ### -------------- Actualización de los pesos ---------------\n  # Aquí vamos a actualizar los pesos, substrayendo una porción de los gradientes\n  \n  \n}\n```\n:::\n\n\nLa propagación hacia adelante efectúa dos transformaciones afines, una para la capa oculta y otra para la capa de salida. En el intermedio se aplica una activación ReLU:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# calculo de las pre-activaciones de las capas ocultas (dim: 100 x 32)\n# torch_mm hace multiplicación de matrices\nh <- x$mm(w1) + b1\n\n# se aplica la función de activación (dim: 100 x 32)\n# torch_clamp corta los valores arriba/abajo de limites dados\nh_relu <- h$clamp(min = 0)\n\n# Calculo de la salida (dim: 100 x 1)\ny_pred <- h_relu$mm(w2) + b2\n```\n:::\n\n\nNuestra función de perdidas es el error cuadrático medio\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloss <- as.numeric((y_pred - y)$pow(2)$sum())\n```\n:::\n\n\nEl calculo manual de los gradientes es un poco tedioso, pero puede ser realizado:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# gradiente de perdidas w.r.t predicción (dim: 100 x 1)\ngrad_y_pred <- 2 * (y_pred - y)\n# gradiente de perdidas w.r.t w2 (dim: 32 x 1)\ngrad_w2 <- h_relu$t()$mm(grad_y_pred)\n# gradiente de perdidas w.r.t activación capa oculta (dim: 100 x 32)\ngrad_h_relu <- grad_y_pre$mm(w2$t())\n# gradiente de perdidas w.r.t pre-activación capa oculta (dim: 100 x 32)\ngrad_h <- grad_h_relu$clone()\n\ngrad_h[h < 0] <- 0\n\n# gradiente de perdidas w.r.t b2 (forma: ())\ngrad_b2 <- grad_y_pred$sum()\n\n# gradiente de perdidas w.r.t w1 (dim 3 x 32)\ngrad_w1 <- x$t()$mm(grad_h)\n# gradiente de perdidas w.r.t b1 (forma: (32, ))\ngrad_b1 <- grad_h$sum(dim = 1)\n```\n:::\n\n\nEl ultimo paso es entonces usar los gradientes calculado para actualizar los pesos:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlearning_rate <- 1e-4\n\nw2 <- w2 - learning_rate * grad_w2\nb2 <- b2 - learning_rate * grad_b2\nw1 <- w1 - learning_rate * grad_w1\nb1 <- b1 - learning_rate * grad_b1\n```\n:::\n\n\nUsando estos fragmentos de código podemos ahora llenar el formato anterior y hacer pruebas!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(torch)\n\n### generate training data -----------------------------------------------------\n\n# input dimensionality (number of input features)\nd_in <- 3\n# output dimensionality (number of predicted features)\nd_out <- 1\n# number of observations in training set\nn <- 100\n\n\n# create random data\nx <- torch_randn(n, d_in)\ny <-\n  x[, 1, NULL] * 0.2 - x[, 2, NULL] * 1.3 - x[, 3, NULL] * 0.5 + torch_randn(n, 1)\n\n\n### initialize weights ---------------------------------------------------------\n\n# dimensionality of hidden layer\nd_hidden <- 32\n# weights connecting input to hidden layer\nw1 <- torch_randn(d_in, d_hidden)\n# weights connecting hidden to output layer\nw2 <- torch_randn(d_hidden, d_out)\n\n# hidden layer bias\nb1 <- torch_zeros(1, d_hidden)\n# output layer bias\nb2 <- torch_zeros(1, d_out)\n\n### network parameters ---------------------------------------------------------\n\nlearning_rate <- 1e-4\n\n### training loop --------------------------------------------------------------\n\nfor (t in 1:200) {\n  ### -------- Forward pass --------\n  \n  # compute pre-activations of hidden layers (dim: 100 x 32)\n  h <- x$mm(w1) + b1\n  # apply activation function (dim: 100 x 32)\n  h_relu <- h$clamp(min = 0)\n  # compute output (dim: 100 x 1)\n  y_pred <- h_relu$mm(w2) + b2\n  \n  ### -------- compute loss --------\n\n  loss <- as.numeric((y_pred - y)$pow(2)$sum())\n  \n  if (t %% 10 == 0)\n    cat(\"Epoch: \", t, \"   Loss: \", loss, \"\\n\")\n  \n  ### -------- Backpropagation --------\n  \n  # gradient of loss w.r.t. prediction (dim: 100 x 1)\n  grad_y_pred <- 2 * (y_pred - y)\n  # gradient of loss w.r.t. w2 (dim: 32 x 1)\n  grad_w2 <- h_relu$t()$mm(grad_y_pred)\n  # gradient of loss w.r.t. hidden activation (dim: 100 x 32)\n  grad_h_relu <- grad_y_pred$mm(\n    w2$t())\n  # gradient of loss w.r.t. hidden pre-activation (dim: 100 x 32)\n  grad_h <- grad_h_relu$clone()\n  \n  grad_h[h < 0] <- 0\n  \n  # gradient of loss w.r.t. b2 (shape: ())\n  grad_b2 <- grad_y_pred$sum()\n  \n  # gradient of loss w.r.t. w1 (dim: 3 x 32)\n  grad_w1 <- x$t()$mm(grad_h)\n  # gradient of loss w.r.t. b1 (shape: (32, ))\n  grad_b1 <- grad_h$sum(dim = 1)\n  \n  ### -------- Update weights --------\n  \n  w2 <- w2 - learning_rate * grad_w2\n  b2 <- b2 - learning_rate * grad_b2\n  w1 <- w1 - learning_rate * grad_w1\n  b1 <- b1 - learning_rate * grad_b1\n  \n}\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch:  10    Loss:  239.8459 \nEpoch:  20    Loss:  175.6584 \nEpoch:  30    Loss:  142.8526 \nEpoch:  40    Loss:  123.4776 \nEpoch:  50    Loss:  110.2153 \nEpoch:  60    Loss:  101.4229 \nEpoch:  70    Loss:  95.29362 \nEpoch:  80    Loss:  90.94321 \nEpoch:  90    Loss:  87.41534 \nEpoch:  100    Loss:  84.34146 \nEpoch:  110    Loss:  81.86013 \nEpoch:  120    Loss:  79.76909 \nEpoch:  130    Loss:  77.94298 \nEpoch:  140    Loss:  76.36224 \nEpoch:  150    Loss:  74.9823 \nEpoch:  160    Loss:  73.76436 \nEpoch:  170    Loss:  72.68542 \nEpoch:  180    Loss:  71.69421 \nEpoch:  190    Loss:  70.77998 \nEpoch:  200    Loss:  69.95052 \n```\n:::\n:::\n\n\nParece que funciona bastante bien! También se ha cumplido con el propósito inicial: mostrar todo lo que se puede conseguir usando únicamente tensores con *torch*. En caso que no te sientas entusiasmado con el desarrollo de la lógica de propagación hacia atrás, no te preocupes, en la próxima entrega esto será significativamente menos exigente. Nos veremos entonces!\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}